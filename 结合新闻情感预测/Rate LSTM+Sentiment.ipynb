{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c91c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Concatenate\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"转换时间序列为监督学习格式\"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    for i in range(n_in, 0, -1):  # 输入序列 (t-n_in, ..., t-1)\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    for i in range(0, n_out):  # 预测序列 (t, t+1, ...)\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "\n",
    "class MultiModalCurrencyLSTMModel:\n",
    "    def __init__(self, price_path, sentiment_path, look_back=10):\n",
    "        self.price_path = price_path\n",
    "        self.sentiment_path = sentiment_path\n",
    "        self.look_back = look_back\n",
    "        # 分别为价格和情绪量表\n",
    "        self.scaler_price = MinMaxScaler(feature_range=(0, 1))\n",
    "        self.scaler_sentiment = MinMaxScaler(feature_range=(0, 1))\n",
    "        self.scaler_y = MinMaxScaler(feature_range=(0, 1))  # 仅对y做归一化\n",
    "        self.model = None\n",
    "\n",
    "    def load_and_prepare_data(self):\n",
    "        # 1. 读取CSV数据\n",
    "        price_df = read_csv(self.price_path, header=0, index_col=0)\n",
    "        sentiment_df = read_csv(self.sentiment_path, header=0, index_col=0)\n",
    "\n",
    "        price_values = price_df.values.astype('float32')  # 价格序列\n",
    "        sentiment_values = sentiment_df.values.astype('float32')  # 情绪序列\n",
    "\n",
    "        # 2. 分别归一化\n",
    "        price_scaled = self.scaler_price.fit_transform(price_values)\n",
    "        sentiment_scaled = self.scaler_sentiment.fit_transform(sentiment_values)\n",
    "\n",
    "        # 3. 转为监督学习格式\n",
    "        price_supervised = series_to_supervised(price_scaled, self.look_back, 1)\n",
    "        sentiment_supervised = series_to_supervised(sentiment_scaled, self.look_back, 1)\n",
    "\n",
    "        # 4. 行数对齐（取最短长度），保证对应数据匹配\n",
    "        min_len = min(len(price_supervised), len(sentiment_supervised))\n",
    "        price_supervised = price_supervised.iloc[-min_len:]\n",
    "        sentiment_supervised = sentiment_supervised.iloc[-min_len:]\n",
    "\n",
    "        price_values = price_supervised.values\n",
    "        sentiment_values = sentiment_supervised.values\n",
    "\n",
    "        # 5. 分训练集和测试集（默认70%训练）\n",
    "        train_size = int(min_len * 0.7)\n",
    "        price_train = price_values[:train_size, :]\n",
    "        price_test = price_values[train_size:, :]\n",
    "        sentiment_train = sentiment_values[:train_size, :]\n",
    "        sentiment_test = sentiment_values[train_size:, :]\n",
    "\n",
    "        # 6. 拆分为X特征和y目标\n",
    "        price_train_X, price_train_y = price_train[:, :-1], price_train[:, -1]\n",
    "        price_test_X, price_test_y = price_test[:, :-1], price_test[:, -1]\n",
    "        sentiment_train_X = sentiment_train[:, :-1]\n",
    "        sentiment_test_X = sentiment_test[:, :-1]\n",
    "\n",
    "        # 7. 目标y归一化，方便模型训练\n",
    "        price_train_y = price_train_y.reshape(-1, 1)\n",
    "        price_test_y = price_test_y.reshape(-1, 1)\n",
    "        self.scaler_y.fit(price_train_y)\n",
    "        price_train_y = self.scaler_y.transform(price_train_y)\n",
    "        price_test_y = self.scaler_y.transform(price_test_y)\n",
    "\n",
    "        # 8. 形状重塑成RNN(样本数, 时间步长, 特征数=1)\n",
    "        price_train_X = price_train_X.reshape((price_train_X.shape[0], self.look_back, 1))\n",
    "        price_test_X = price_test_X.reshape((price_test_X.shape[0], self.look_back, 1))\n",
    "        sentiment_train_X = sentiment_train_X.reshape((sentiment_train_X.shape[0], self.look_back, 1))\n",
    "        sentiment_test_X = sentiment_test_X.reshape((sentiment_test_X.shape[0], self.look_back, 1))\n",
    "\n",
    "        return (price_train_X, sentiment_train_X, price_train_y), (price_test_X, sentiment_test_X, price_test_y)\n",
    "\n",
    "    def build_model(self):\n",
    "        # 价格输入分支\n",
    "        price_input = Input(shape=(self.look_back, 1), name=\"price_input\")\n",
    "        price_lstm = LSTM(50, return_sequences=True, kernel_regularizer=l2(0.01))(price_input)\n",
    "        price_lstm = Dropout(0.3)(price_lstm)\n",
    "        price_lstm = LSTM(100, return_sequences=False, kernel_regularizer=l2(0.01))(price_lstm)\n",
    "        price_lstm = Dropout(0.3)(price_lstm)\n",
    "\n",
    "        # 情绪输入分支\n",
    "        sentiment_input = Input(shape=(self.look_back, 1), name=\"sentiment_input\")\n",
    "        sentiment_lstm = LSTM(30, return_sequences=True, kernel_regularizer=l2(0.01))(sentiment_input)\n",
    "        sentiment_lstm = Dropout(0.3)(sentiment_lstm)\n",
    "        sentiment_lstm = LSTM(60, return_sequences=False, kernel_regularizer=l2(0.01))(sentiment_lstm)\n",
    "        sentiment_lstm = Dropout(0.3)(sentiment_lstm)\n",
    "\n",
    "        # 融合\n",
    "        merged = Concatenate()([price_lstm, sentiment_lstm])\n",
    "\n",
    "        # 全连接层\n",
    "        dense1 = Dense(50, activation='relu')(merged)\n",
    "        dense2 = Dropout(0.3)(dense1)\n",
    "        output = Dense(1)(dense2)\n",
    "\n",
    "        model = Model(inputs=[price_input, sentiment_input], outputs=output)\n",
    "        model.compile(loss='mae', optimizer='adam')\n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def train(self, epochs=100, batch_size=64):\n",
    "        (price_train_X, sentiment_train_X, train_y), (price_test_X, sentiment_test_X, test_y) = self.load_and_prepare_data()\n",
    "        self.build_model()\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "        history = self.model.fit(\n",
    "            [price_train_X, sentiment_train_X], train_y,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=([price_test_X, sentiment_test_X], test_y),\n",
    "            verbose=2,\n",
    "            shuffle=False,\n",
    "            callbacks=[early_stopping, lr_scheduler]\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def predict(self, price_X, sentiment_X):\n",
    "        yhat = self.model.predict([price_X, sentiment_X])\n",
    "        # 逆归一化输出\n",
    "        yhat_inv = self.scaler_y.inverse_transform(yhat)\n",
    "        return yhat_inv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267537c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 - 3s - 718ms/step - loss: 1.7384 - val_loss: 1.9017 - learning_rate: 0.0010\n",
      "Epoch 2/500\n",
      "4/4 - 0s - 22ms/step - loss: 1.5095 - val_loss: 1.5412 - learning_rate: 0.0010\n",
      "Epoch 3/500\n",
      "4/4 - 0s - 22ms/step - loss: 1.3825 - val_loss: 1.2932 - learning_rate: 0.0010\n",
      "Epoch 4/500\n",
      "4/4 - 0s - 23ms/step - loss: 1.2569 - val_loss: 1.2383 - learning_rate: 0.0010\n",
      "Epoch 5/500\n",
      "4/4 - 0s - 23ms/step - loss: 1.1431 - val_loss: 1.2061 - learning_rate: 0.0010\n",
      "Epoch 6/500\n",
      "4/4 - 0s - 23ms/step - loss: 1.0523 - val_loss: 1.0735 - learning_rate: 0.0010\n",
      "Epoch 7/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.9536 - val_loss: 0.9044 - learning_rate: 0.0010\n",
      "Epoch 8/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.8793 - val_loss: 0.8096 - learning_rate: 0.0010\n",
      "Epoch 9/500\n",
      "4/4 - 0s - 24ms/step - loss: 0.8048 - val_loss: 0.7595 - learning_rate: 0.0010\n",
      "Epoch 10/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.7458 - val_loss: 0.7272 - learning_rate: 0.0010\n",
      "Epoch 11/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.6861 - val_loss: 0.6382 - learning_rate: 0.0010\n",
      "Epoch 12/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.6368 - val_loss: 0.5959 - learning_rate: 0.0010\n",
      "Epoch 13/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.5809 - val_loss: 0.5657 - learning_rate: 0.0010\n",
      "Epoch 14/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.5371 - val_loss: 0.5371 - learning_rate: 0.0010\n",
      "Epoch 15/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.5019 - val_loss: 0.4761 - learning_rate: 0.0010\n",
      "Epoch 16/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.4585 - val_loss: 0.4430 - learning_rate: 0.0010\n",
      "Epoch 17/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.4309 - val_loss: 0.3980 - learning_rate: 0.0010\n",
      "Epoch 18/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.4061 - val_loss: 0.3897 - learning_rate: 0.0010\n",
      "Epoch 19/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.3869 - val_loss: 0.3809 - learning_rate: 0.0010\n",
      "Epoch 20/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.3524 - val_loss: 0.3273 - learning_rate: 0.0010\n",
      "Epoch 21/500\n",
      "4/4 - 0s - 20ms/step - loss: 0.3305 - val_loss: 0.3032 - learning_rate: 0.0010\n",
      "Epoch 22/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.3114 - val_loss: 0.2859 - learning_rate: 0.0010\n",
      "Epoch 23/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.2933 - val_loss: 0.2775 - learning_rate: 0.0010\n",
      "Epoch 24/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.2776 - val_loss: 0.2772 - learning_rate: 0.0010\n",
      "Epoch 25/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.2680 - val_loss: 0.2595 - learning_rate: 0.0010\n",
      "Epoch 26/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.2416 - val_loss: 0.2350 - learning_rate: 0.0010\n",
      "Epoch 27/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.2318 - val_loss: 0.2263 - learning_rate: 0.0010\n",
      "Epoch 28/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.2307 - val_loss: 0.2054 - learning_rate: 0.0010\n",
      "Epoch 29/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.2202 - val_loss: 0.2100 - learning_rate: 0.0010\n",
      "Epoch 30/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.2041 - val_loss: 0.2103 - learning_rate: 0.0010\n",
      "Epoch 31/500\n",
      "4/4 - 0s - 23ms/step - loss: 0.1947 - val_loss: 0.1933 - learning_rate: 0.0010\n",
      "Epoch 32/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1916 - val_loss: 0.1747 - learning_rate: 0.0010\n",
      "Epoch 33/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1788 - val_loss: 0.2032 - learning_rate: 0.0010\n",
      "Epoch 34/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1772 - val_loss: 0.1739 - learning_rate: 0.0010\n",
      "Epoch 35/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1693 - val_loss: 0.1570 - learning_rate: 0.0010\n",
      "Epoch 36/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1682 - val_loss: 0.1603 - learning_rate: 0.0010\n",
      "Epoch 37/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1625 - val_loss: 0.1550 - learning_rate: 0.0010\n",
      "Epoch 38/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1570 - val_loss: 0.1530 - learning_rate: 0.0010\n",
      "Epoch 39/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1521 - val_loss: 0.1504 - learning_rate: 0.0010\n",
      "Epoch 40/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1454 - val_loss: 0.1416 - learning_rate: 0.0010\n",
      "Epoch 41/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1470 - val_loss: 0.1412 - learning_rate: 0.0010\n",
      "Epoch 42/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1462 - val_loss: 0.1396 - learning_rate: 0.0010\n",
      "Epoch 43/500\n",
      "4/4 - 0s - 26ms/step - loss: 0.1370 - val_loss: 0.1430 - learning_rate: 0.0010\n",
      "Epoch 44/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1410 - val_loss: 0.1499 - learning_rate: 0.0010\n",
      "Epoch 45/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1368 - val_loss: 0.1449 - learning_rate: 0.0010\n",
      "Epoch 46/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1348 - val_loss: 0.1388 - learning_rate: 0.0010\n",
      "Epoch 47/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1319 - val_loss: 0.1357 - learning_rate: 0.0010\n",
      "Epoch 48/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1347 - val_loss: 0.1529 - learning_rate: 0.0010\n",
      "Epoch 49/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1297 - val_loss: 0.1189 - learning_rate: 0.0010\n",
      "Epoch 50/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1257 - val_loss: 0.1130 - learning_rate: 0.0010\n",
      "Epoch 51/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1250 - val_loss: 0.1871 - learning_rate: 0.0010\n",
      "Epoch 52/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1257 - val_loss: 0.1140 - learning_rate: 0.0010\n",
      "Epoch 53/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1246 - val_loss: 0.1204 - learning_rate: 0.0010\n",
      "Epoch 54/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1227 - val_loss: 0.1843 - learning_rate: 0.0010\n",
      "Epoch 55/500\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 - 0s - 21ms/step - loss: 0.1247 - val_loss: 0.1141 - learning_rate: 0.0010\n",
      "Epoch 56/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1091 - val_loss: 0.1064 - learning_rate: 5.0000e-04\n",
      "Epoch 57/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1135 - val_loss: 0.1220 - learning_rate: 5.0000e-04\n",
      "Epoch 58/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1209 - val_loss: 0.1365 - learning_rate: 5.0000e-04\n",
      "Epoch 59/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1184 - val_loss: 0.1086 - learning_rate: 5.0000e-04\n",
      "Epoch 60/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1208 - val_loss: 0.1050 - learning_rate: 5.0000e-04\n",
      "Epoch 61/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1139 - val_loss: 0.1174 - learning_rate: 5.0000e-04\n",
      "Epoch 62/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1090 - val_loss: 0.1195 - learning_rate: 5.0000e-04\n",
      "Epoch 63/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1123 - val_loss: 0.1192 - learning_rate: 5.0000e-04\n",
      "Epoch 64/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1130 - val_loss: 0.1179 - learning_rate: 5.0000e-04\n",
      "Epoch 65/500\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 - 0s - 22ms/step - loss: 0.1171 - val_loss: 0.1358 - learning_rate: 5.0000e-04\n",
      "Epoch 66/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1160 - val_loss: 0.1368 - learning_rate: 2.5000e-04\n",
      "Epoch 67/500\n",
      "4/4 - 0s - 21ms/step - loss: 0.1122 - val_loss: 0.1211 - learning_rate: 2.5000e-04\n",
      "Epoch 68/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1111 - val_loss: 0.1115 - learning_rate: 2.5000e-04\n",
      "Epoch 69/500\n",
      "4/4 - 0s - 22ms/step - loss: 0.1099 - val_loss: 0.1080 - learning_rate: 2.5000e-04\n",
      "Epoch 70/500\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 - 0s - 22ms/step - loss: 0.1075 - val_loss: 0.1178 - learning_rate: 2.5000e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "MAE: 0.0626, RMSE: 0.0780\n",
      "模型对测试集的预测结果：\n",
      "[0.4261206  0.42216918 0.4155816  0.40750882 0.40139756 0.40218797\n",
      " 0.40560326 0.41350642 0.42151728 0.44467276 0.48559582 0.52591974\n",
      " 0.560473   0.5862214  0.60863197 0.6355266  0.66360307 0.69379455\n",
      " 0.71773595 0.74754584 0.77727574 0.79903454 0.81562227 0.8254574\n",
      " 0.8343758  0.84634197 0.85559916 0.8688206  0.8854893  0.89204663\n",
      " 0.8895064  0.8728035  0.8479764  0.8210105  0.8013713  0.791439\n",
      " 0.7881796  0.77960205 0.7715693  0.7520546  0.73086274 0.71348935\n",
      " 0.70427734 0.7009586  0.6968463  0.69161254 0.6838568  0.666796\n",
      " 0.63555694 0.5940281  0.5577312  0.5390985  0.5326948  0.5378359\n",
      " 0.54643595 0.5635591  0.585997   0.6137948  0.6324809  0.6506205\n",
      " 0.67025656 0.6887066  0.7018053  0.7033307  0.69023323 0.6736016\n",
      " 0.65731376 0.64700097 0.64111316 0.6489736  0.6577677  0.66901535\n",
      " 0.6759477  0.6715881  0.6590646  0.6438449  0.63082296 0.61821806\n",
      " 0.61063576 0.6145751  0.61852914 0.6287644  0.63664347 0.64055735\n",
      " 0.63822687 0.6333875  0.62260634 0.60516644 0.58547616 0.5676467\n",
      " 0.5507854  0.5433024  0.5417194  0.54912657 0.55915666 0.57316834\n",
      " 0.5847597  0.5942437  0.60468286 0.614404   0.6159161  0.61611694\n",
      " 0.6121244  0.6091293  0.5994     0.5815128  0.5598209 ]\n",
      "测试集真实汇率：\n",
      "[0.37560225 0.37244463 0.3927207  0.41632032 0.41632032 0.40917444\n",
      " 0.45288324 0.41648626 0.6526513  0.68622255 0.6077781  0.6077781\n",
      " 0.5899949  0.66461706 0.78078794 0.7859397  0.8150239  0.80388886\n",
      " 0.80388886 0.8520856  0.8608937  0.8733592  0.88831663 0.891973\n",
      " 0.8972916  0.8972916  0.9634366  1.0000005  0.8635535  0.8490939\n",
      " 0.7811198  0.7887645  0.789928   0.8514208  0.85790205 0.83463526\n",
      " 0.6686053  0.72926664 0.6880498  0.6880498  0.75735426 0.7525344\n",
      " 0.73608065 0.6323743  0.6508231  0.6408515  0.6408515  0.43609762\n",
      " 0.45969722 0.5336547  0.5793586  0.56689405 0.59514666 0.59514666\n",
      " 0.6300483  0.64965963 0.6918731  0.6863885  0.7304301  0.7340865\n",
      " 0.7340865  0.7234502  0.6425128  0.6052842  0.64301157 0.6632867\n",
      " 0.67143106 0.67143106 0.74688387 0.6651149  0.7093234  0.6499915\n",
      " 0.6132617  0.61509085 0.61509085 0.62240267 0.6022935  0.6292167\n",
      " 0.6574702  0.64301157 0.6529832  0.6529832  0.6411834  0.58916426\n",
      " 0.6217389  0.5614095  0.5404687  0.53149366 0.53149366 0.5133786\n",
      " 0.5889983  0.5544286  0.617085   0.5986371  0.6032901  0.6032901\n",
      " 0.61243105 0.65514326 0.64699984 0.5838456  0.60096407 0.6067805\n",
      " 0.6067805  0.5386405  0.48678732 0.5039058  0.51720095]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "model = MultiModalCurrencyLSTMModel('CNY_JPY_to_exchange_rate.csv', 'JPY_sentiment.csv', look_back=10)\n",
    "history = model.train(epochs=500, batch_size=64)\n",
    "\n",
    "(price_train_X, sentiment_train_X, train_y), (price_test_X, sentiment_test_X, test_y) = model.load_and_prepare_data()\n",
    "predictions = model.predict(price_test_X, sentiment_test_X)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "y_true = model.scaler_y.inverse_transform(test_y.reshape(-1, 1))\n",
    "mae = mean_absolute_error(y_true, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, predictions))\n",
    "print(f'MAE: {mae:.4f}, RMSE: {rmse:.4f}')\n",
    "\n",
    "# 输出预测结果\n",
    "print(\"模型对测试集的预测结果：\")\n",
    "print(predictions.flatten())\n",
    "\n",
    "# 可选：对比真实值\n",
    "y_true = model.scaler_y.inverse_transform(test_y.reshape(-1, 1))\n",
    "print(\"测试集真实汇率：\")\n",
    "print(y_true.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1390c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def create_prediction_api(model, currency_pair='JPY', days=20):\n",
    "    \"\"\"\n",
    "    创建用于前端调用的预测API函数\n",
    "    \n",
    "    Args:\n",
    "        model: 训练好的MultiModalCurrencyLSTMModel实例\n",
    "        currency_pair: 货币对代码 (如 'JPY', 'HKD', 'SGD' 等)\n",
    "        days: 预测天数\n",
    "    \n",
    "    Returns:\n",
    "        dict: 包含预测结果的字典\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 获取最新的历史数据进行预测\n",
    "        price_df = pd.read_csv(f'CNY_{currency_pair}_to_exchange_rate.csv', header=0, index_col=0)\n",
    "        sentiment_df = pd.read_csv(f'{currency_pair}_sentiment.csv', header=0, index_col=0)\n",
    "        \n",
    "        # 获取最近的数据作为输入\n",
    "        recent_price = price_df.values[-model.look_back:].astype('float32')\n",
    "        recent_sentiment = sentiment_df.values[-model.look_back:].astype('float32')\n",
    "        \n",
    "        # 数据预处理 - 使用已训练好的scaler\n",
    "        price_scaled = model.scaler_price.transform(recent_price)\n",
    "        sentiment_scaled = model.scaler_sentiment.transform(recent_sentiment)\n",
    "        \n",
    "        # 重塑为模型输入格式\n",
    "        price_input = price_scaled.reshape(1, model.look_back, 1)\n",
    "        sentiment_input = sentiment_scaled.reshape(1, model.look_back, 1)\n",
    "        \n",
    "        # 生成多天预测\n",
    "        predictions = []\n",
    "        current_price_seq = price_input.copy()\n",
    "        current_sentiment_seq = sentiment_input.copy()\n",
    "        \n",
    "        base_date = datetime.now()\n",
    "        \n",
    "        for i in range(days):\n",
    "            # 预测下一天\n",
    "            pred = model.predict(current_price_seq, current_sentiment_seq)\n",
    "            pred_value = float(pred[0, 0])\n",
    "            \n",
    "            # 添加到结果列表\n",
    "            pred_date = (base_date + timedelta(days=i+1)).strftime('%Y-%m-%d')\n",
    "            predictions.append({\n",
    "                'date': pred_date,\n",
    "                'rate': round(pred_value, 4),\n",
    "                'timestamp': int((base_date + timedelta(days=i+1)).timestamp() * 1000)\n",
    "            })\n",
    "            \n",
    "            # 更新输入序列 - 将预测值作为下一次的输入\n",
    "            # 对预测值进行归一化\n",
    "            pred_normalized = model.scaler_price.transform([[pred_value]])\n",
    "            \n",
    "            # 滚动更新价格序列\n",
    "            new_price_seq = np.roll(current_price_seq, -1, axis=1)\n",
    "            new_price_seq[0, -1, 0] = pred_normalized[0, 0]\n",
    "            current_price_seq = new_price_seq\n",
    "            \n",
    "            # 情感序列保持最后一个值（简化处理）\n",
    "            new_sentiment_seq = np.roll(current_sentiment_seq, -1, axis=1)\n",
    "            new_sentiment_seq[0, -1, 0] = current_sentiment_seq[0, -1, 0]\n",
    "            current_sentiment_seq = new_sentiment_seq\n",
    "        \n",
    "        # 找出最佳购买时机（汇率最高点）\n",
    "        rates = [p['rate'] for p in predictions]\n",
    "        max_rate_idx = np.argmax(rates)\n",
    "        predictions[max_rate_idx]['isOptimal'] = True\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'currency_pair': f'CNY_{currency_pair}',\n",
    "            'predictions': predictions,\n",
    "            'model_info': {\n",
    "                'model_type': 'LSTM+Sentiment',\n",
    "                'look_back': model.look_back,\n",
    "                'prediction_days': days\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'currency_pair': f'CNY_{currency_pair}'\n",
    "        }\n",
    "\n",
    "# 训练好模型后，创建预测函数\n",
    "def predict_exchange_rate(currency_pair, days=20):\n",
    "    \"\"\"\n",
    "    对外提供的预测接口\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 加载对应的模型（这里假设模型已经训练并保存）\n",
    "        model = MultiModalCurrencyLSTMModel(\n",
    "            f'CNY_{currency_pair}_to_exchange_rate.csv', \n",
    "            f'{currency_pair}_sentiment.csv', \n",
    "            look_back=10\n",
    "        )\n",
    "        \n",
    "        # 如果模型文件存在，加载训练好的模型\n",
    "        try:\n",
    "            model.build_model()\n",
    "            model.model.load_weights(f'{currency_pair}_lstm_model.h5')\n",
    "        except:\n",
    "            # 如果没有保存的模型，重新训练\n",
    "            print(f\"No saved model found for {currency_pair}, training new model...\")\n",
    "            model.train(epochs=100, batch_size=64)\n",
    "            # 保存模型\n",
    "            model.model.save_weights(f'{currency_pair}_lstm_model.h5')\n",
    "        \n",
    "        return create_prediction_api(model, currency_pair, days)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': f'Failed to load model for {currency_pair}: {str(e)}'\n",
    "        }\n",
    "\n",
    "print(\"预测API函数已创建完成！\")\n",
    "print(\"可以通过 predict_exchange_rate('JPY', 20) 来调用预测功能\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46856212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
