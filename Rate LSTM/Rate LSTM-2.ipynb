{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c28c999",
   "metadata": {},
   "source": [
    "# 汇率预测机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78aef093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "class CurrencyLSTMModel:\n",
    "    def __init__(self, currency_name, data_path, look_back=1):\n",
    "        self.currency_name = currency_name\n",
    "        self.data_path = data_path\n",
    "        self.look_back = look_back\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        self.model = None\n",
    "\n",
    "    def load_and_prepare_data(self):\n",
    "        dataset = read_csv(self.data_path, header=0, index_col=0)\n",
    "        values = dataset.values.astype('float32')\n",
    "        scaled = self.scaler.fit_transform(values)\n",
    "        \n",
    "        reframed = series_to_supervised(scaled, self.look_back, 1)\n",
    "        values = reframed.values\n",
    "        n_train = int(len(values) * 0.7)\n",
    "        train = values[:n_train, :]\n",
    "        test = values[n_train:, :]\n",
    "        \n",
    "        train_X, train_y = train[:, :-1], train[:, -1]\n",
    "        test_X, test_y = test[:, :-1], test[:, -1]\n",
    "        \n",
    "        train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], 1))\n",
    "        test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], 1))\n",
    "        \n",
    "        return train_X, train_y, test_X, test_y\n",
    "\n",
    "    def build_model(self, input_shape):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, input_shape=input_shape, return_sequences=True, kernel_regularizer=l2(0.01)))\n",
    "        model.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "        model.add(LSTM(100, return_sequences=True, kernel_regularizer=l2(0.01)))\n",
    "        model.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "        model.add(LSTM(50, return_sequences=False, kernel_regularizer=l2(0.01)))\n",
    "        model.add(Dropout(0.3))  # Dropout to prevent overfitting\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mae', optimizer='adam')\n",
    "        self.model = model\n",
    "\n",
    "    def train(self, epochs=100, batch_size=60):\n",
    "        train_X, train_y, test_X, test_y = self.load_and_prepare_data()\n",
    "        self.build_model((train_X.shape[1], train_X.shape[2]))\n",
    "\n",
    "        # Early stopping and learning rate scheduler\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "        # Train the model with early stopping and learning rate scheduling\n",
    "        history = self.model.fit(train_X, train_y, epochs=epochs, batch_size=batch_size,\n",
    "                                 validation_data=(test_X, test_y), verbose=2, shuffle=False,\n",
    "                                 callbacks=[early_stopping, lr_scheduler])\n",
    "        return history\n",
    "\n",
    "    def save(self, model_path):\n",
    "        self.model.save(model_path)\n",
    "\n",
    "    def load(self, model_path):\n",
    "        self.model = load_model(model_path)\n",
    "\n",
    "    def predict(self, X):\n",
    "        yhat = self.model.predict(X)\n",
    "        return yhat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d902d",
   "metadata": {},
   "source": [
    "## 新币汇率预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5090db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测 JPY 对人民币的汇率：\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rprp/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 305 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7f050c1ac0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 - 4s - 2s/step - loss: 0.2742 - val_loss: 0.1743\n",
      "Epoch 2/100\n",
      "2/2 - 1s - 293ms/step - loss: 0.1040 - val_loss: 0.4041\n",
      "Epoch 3/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.2181 - val_loss: 0.2054\n",
      "Epoch 4/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.1417 - val_loss: 0.1293\n",
      "Epoch 5/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.1135 - val_loss: 0.1571\n",
      "Epoch 6/100\n",
      "2/2 - 1s - 257ms/step - loss: 0.1233 - val_loss: 0.1597\n",
      "Epoch 7/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.1176 - val_loss: 0.1462\n",
      "Epoch 8/100\n",
      "2/2 - 1s - 281ms/step - loss: 0.1010 - val_loss: 0.1272\n",
      "Epoch 9/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0979 - val_loss: 0.1200\n",
      "Epoch 10/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.1025 - val_loss: 0.1235\n",
      "Epoch 11/100\n",
      "2/2 - 0s - 228ms/step - loss: 0.1061 - val_loss: 0.1232\n",
      "Epoch 12/100\n",
      "2/2 - 0s - 225ms/step - loss: 0.1061 - val_loss: 0.1185\n",
      "Epoch 13/100\n",
      "2/2 - 0s - 235ms/step - loss: 0.1028 - val_loss: 0.1180\n",
      "Epoch 14/100\n",
      "2/2 - 0s - 227ms/step - loss: 0.0988 - val_loss: 0.1212\n",
      "Epoch 15/100\n",
      "2/2 - 0s - 226ms/step - loss: 0.0963 - val_loss: 0.1251\n",
      "Epoch 16/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0948 - val_loss: 0.1272\n",
      "Epoch 17/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0936 - val_loss: 0.1264\n",
      "Epoch 18/100\n",
      "2/2 - 0s - 250ms/step - loss: 0.0922 - val_loss: 0.1227\n",
      "Epoch 19/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.0904 - val_loss: 0.1172\n",
      "Epoch 20/100\n",
      "2/2 - 1s - 512ms/step - loss: 0.0886 - val_loss: 0.1118\n",
      "Epoch 21/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.0870 - val_loss: 0.1080\n",
      "Epoch 22/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0863 - val_loss: 0.1057\n",
      "Epoch 23/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.0860 - val_loss: 0.1045\n",
      "Epoch 24/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0841 - val_loss: 0.1035\n",
      "Epoch 25/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0819 - val_loss: 0.1031\n",
      "Epoch 26/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0797 - val_loss: 0.1021\n",
      "Epoch 27/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0772 - val_loss: 0.1001\n",
      "Epoch 28/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0742 - val_loss: 0.0972\n",
      "Epoch 29/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0705 - val_loss: 0.0988\n",
      "Epoch 30/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0683 - val_loss: 0.1016\n",
      "Epoch 31/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.0674 - val_loss: 0.1038\n",
      "Epoch 32/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0660 - val_loss: 0.1092\n",
      "Epoch 33/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0633 - val_loss: 0.1141\n",
      "Epoch 34/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0666 - val_loss: 0.1098\n",
      "Epoch 35/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0656 - val_loss: 0.1087\n",
      "Epoch 36/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.0640 - val_loss: 0.1060\n",
      "Epoch 37/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.0644 - val_loss: 0.1015\n",
      "Epoch 38/100\n",
      "2/2 - 1s - 260ms/step - loss: 0.0626 - val_loss: 0.0991\n",
      "Epoch 39/100\n",
      "2/2 - 1s - 262ms/step - loss: 0.0624 - val_loss: 0.0963\n",
      "Epoch 40/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0616 - val_loss: 0.0960\n",
      "Epoch 41/100\n",
      "2/2 - 1s - 305ms/step - loss: 0.0611 - val_loss: 0.0933\n",
      "Epoch 42/100\n",
      "2/2 - 1s - 260ms/step - loss: 0.0610 - val_loss: 0.0928\n",
      "Epoch 43/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0603 - val_loss: 0.0942\n",
      "Epoch 44/100\n",
      "2/2 - 1s - 274ms/step - loss: 0.0607 - val_loss: 0.0877\n",
      "Epoch 45/100\n",
      "2/2 - 1s - 253ms/step - loss: 0.0604 - val_loss: 0.0914\n",
      "Epoch 46/100\n",
      "2/2 - 1s - 266ms/step - loss: 0.0599 - val_loss: 0.0916\n",
      "Epoch 47/100\n",
      "2/2 - 1s - 253ms/step - loss: 0.0599 - val_loss: 0.0885\n",
      "Epoch 48/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.0601 - val_loss: 0.0891\n",
      "Epoch 49/100\n",
      "2/2 - 1s - 257ms/step - loss: 0.0591 - val_loss: 0.0934\n",
      "Epoch 50/100\n",
      "2/2 - 0s - 228ms/step - loss: 0.0598 - val_loss: 0.0873\n",
      "Epoch 51/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0598 - val_loss: 0.0869\n",
      "Epoch 52/100\n",
      "2/2 - 0s - 223ms/step - loss: 0.0584 - val_loss: 0.0965\n",
      "Epoch 53/100\n",
      "2/2 - 0s - 213ms/step - loss: 0.0596 - val_loss: 0.0878\n",
      "Epoch 54/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0591 - val_loss: 0.0831\n",
      "Epoch 55/100\n",
      "2/2 - 1s - 258ms/step - loss: 0.0590 - val_loss: 0.0917\n",
      "Epoch 56/100\n",
      "2/2 - 1s - 277ms/step - loss: 0.0587 - val_loss: 0.0906\n",
      "Epoch 57/100\n",
      "2/2 - 1s - 264ms/step - loss: 0.0586 - val_loss: 0.0843\n",
      "Epoch 58/100\n",
      "2/2 - 1s - 265ms/step - loss: 0.0584 - val_loss: 0.0883\n",
      "Epoch 59/100\n",
      "2/2 - 1s - 252ms/step - loss: 0.0576 - val_loss: 0.0965\n",
      "Epoch 60/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0584 - val_loss: 0.0855\n",
      "Epoch 61/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.0577 - val_loss: 0.0828\n",
      "Epoch 62/100\n",
      "2/2 - 1s - 261ms/step - loss: 0.0574 - val_loss: 0.0920\n",
      "Epoch 63/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.0575 - val_loss: 0.0911\n",
      "Epoch 64/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.0576 - val_loss: 0.0826\n",
      "Epoch 65/100\n",
      "2/2 - 0s - 221ms/step - loss: 0.0570 - val_loss: 0.0868\n",
      "Epoch 66/100\n",
      "2/2 - 1s - 341ms/step - loss: 0.0568 - val_loss: 0.0888\n",
      "Epoch 67/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.0569 - val_loss: 0.0834\n",
      "Epoch 68/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0565 - val_loss: 0.0847\n",
      "Epoch 69/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0562 - val_loss: 0.0873\n",
      "Epoch 70/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.0564 - val_loss: 0.0813\n",
      "Epoch 71/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.0561 - val_loss: 0.0820\n",
      "Epoch 72/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.0557 - val_loss: 0.0878\n",
      "Epoch 73/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0561 - val_loss: 0.0799\n",
      "Epoch 74/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.0557 - val_loss: 0.0936\n",
      "Epoch 75/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0560 - val_loss: 0.0901\n",
      "Epoch 76/100\n",
      "2/2 - 1s - 264ms/step - loss: 0.0558 - val_loss: 0.0808\n",
      "Epoch 77/100\n",
      "2/2 - 1s - 259ms/step - loss: 0.0558 - val_loss: 0.1033\n",
      "Epoch 78/100\n",
      "2/2 - 1s - 262ms/step - loss: 0.0565 - val_loss: 0.0815\n",
      "Epoch 79/100\n",
      "2/2 - 1s - 279ms/step - loss: 0.0545 - val_loss: 0.0925\n",
      "Epoch 80/100\n",
      "2/2 - 1s - 277ms/step - loss: 0.0551 - val_loss: 0.0778\n",
      "Epoch 81/100\n",
      "2/2 - 1s - 270ms/step - loss: 0.0547 - val_loss: 0.0842\n",
      "Epoch 82/100\n",
      "2/2 - 0s - 235ms/step - loss: 0.0548 - val_loss: 0.0882\n",
      "Epoch 83/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.0547 - val_loss: 0.0756\n",
      "Epoch 84/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0541 - val_loss: 0.0898\n",
      "Epoch 85/100\n",
      "2/2 - 1s - 441ms/step - loss: 0.0542 - val_loss: 0.0757\n",
      "Epoch 86/100\n",
      "2/2 - 1s - 266ms/step - loss: 0.0548 - val_loss: 0.0844\n",
      "Epoch 87/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0543 - val_loss: 0.0876\n",
      "Epoch 88/100\n",
      "2/2 - 0s - 250ms/step - loss: 0.0556 - val_loss: 0.0739\n",
      "Epoch 89/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0530 - val_loss: 0.0906\n",
      "Epoch 90/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.0534 - val_loss: 0.0781\n",
      "Epoch 91/100\n",
      "2/2 - 1s - 326ms/step - loss: 0.0532 - val_loss: 0.0998\n",
      "Epoch 92/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.0543 - val_loss: 0.0831\n",
      "Epoch 93/100\n",
      "2/2 - 1s - 259ms/step - loss: 0.0540 - val_loss: 0.0794\n",
      "Epoch 94/100\n",
      "2/2 - 1s - 264ms/step - loss: 0.0522 - val_loss: 0.0973\n",
      "Epoch 95/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0532 - val_loss: 0.0755\n",
      "Epoch 96/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0523 - val_loss: 0.0877\n",
      "Epoch 97/100\n",
      "2/2 - 1s - 256ms/step - loss: 0.0532 - val_loss: 0.0815\n",
      "Epoch 98/100\n",
      "2/2 - 0s - 207ms/step - loss: 0.0525 - val_loss: 0.0778\n",
      "Epoch 99/100\n",
      "2/2 - 0s - 217ms/step - loss: 0.0518 - val_loss: 0.0843\n",
      "Epoch 100/100\n",
      "2/2 - 0s - 204ms/step - loss: 0.0517 - val_loss: 0.0785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "未来20天预测汇率：\n",
      "[0.04527146 0.04517519 0.04511571 0.04509012 0.04509325 0.04511961\n",
      " 0.04516446 0.04522411 0.04529594 0.04537812 0.04546938 0.04556879\n",
      " 0.04567556 0.04578898 0.04590832 0.04603281 0.04616169 0.04629419\n",
      " 0.04642956 0.04656708]\n",
      "------------------------------\n",
      "预测 KRW 对人民币的汇率：\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rprp/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 5s - 3s/step - loss: 0.4409 - val_loss: 0.5771\n",
      "Epoch 2/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.2970 - val_loss: 0.2600\n",
      "Epoch 3/100\n",
      "2/2 - 1s - 268ms/step - loss: 0.1113 - val_loss: 0.3804\n",
      "Epoch 4/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.2285 - val_loss: 0.0965\n",
      "Epoch 5/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.1398 - val_loss: 0.1505\n",
      "Epoch 6/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.1518 - val_loss: 0.2046\n",
      "Epoch 7/100\n",
      "2/2 - 1s - 256ms/step - loss: 0.1523 - val_loss: 0.1758\n",
      "Epoch 8/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.1310 - val_loss: 0.1017\n",
      "Epoch 9/100\n",
      "2/2 - 0s - 233ms/step - loss: 0.1099 - val_loss: 0.0736\n",
      "Epoch 10/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.1180 - val_loss: 0.1278\n",
      "Epoch 11/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.1290 - val_loss: 0.1007\n",
      "Epoch 12/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.1180 - val_loss: 0.0661\n",
      "Epoch 13/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.1096 - val_loss: 0.0710\n",
      "Epoch 14/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.1069 - val_loss: 0.0763\n",
      "Epoch 15/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.1047 - val_loss: 0.0685\n",
      "Epoch 16/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0994 - val_loss: 0.0677\n",
      "Epoch 17/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0935 - val_loss: 0.1219\n",
      "Epoch 18/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.0952 - val_loss: 0.1650\n",
      "Epoch 19/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0933 - val_loss: 0.1332\n",
      "Epoch 20/100\n",
      "2/2 - 1s - 275ms/step - loss: 0.0890 - val_loss: 0.0912\n",
      "Epoch 21/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0903 - val_loss: 0.0826\n",
      "Epoch 22/100\n",
      "2/2 - 1s - 297ms/step - loss: 0.0895 - val_loss: 0.1208\n",
      "Epoch 23/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0877 - val_loss: 0.1840\n",
      "Epoch 24/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0889 - val_loss: 0.2039\n",
      "Epoch 25/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.0869 - val_loss: 0.1703\n",
      "Epoch 26/100\n",
      "2/2 - 1s - 263ms/step - loss: 0.0865 - val_loss: 0.1410\n",
      "Epoch 27/100\n",
      "2/2 - 1s - 262ms/step - loss: 0.0876 - val_loss: 0.1427\n",
      "Epoch 28/100\n",
      "2/2 - 1s - 256ms/step - loss: 0.0871 - val_loss: 0.1694\n",
      "Epoch 29/100\n",
      "2/2 - 1s - 256ms/step - loss: 0.0867 - val_loss: 0.1866\n",
      "Epoch 30/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0856 - val_loss: 0.1649\n",
      "Epoch 31/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0845 - val_loss: 0.1331\n",
      "Epoch 32/100\n",
      "2/2 - 1s - 259ms/step - loss: 0.0850 - val_loss: 0.1222\n",
      "Epoch 33/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0848 - val_loss: 0.1375\n",
      "Epoch 34/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0840 - val_loss: 0.1588\n",
      "Epoch 35/100\n",
      "2/2 - 1s - 550ms/step - loss: 0.0836 - val_loss: 0.1547\n",
      "Epoch 36/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0827 - val_loss: 0.1373\n",
      "Epoch 37/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0827 - val_loss: 0.1418\n",
      "Epoch 38/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0823 - val_loss: 0.1504\n",
      "Epoch 39/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0816 - val_loss: 0.1430\n",
      "Epoch 40/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0813 - val_loss: 0.1546\n",
      "Epoch 41/100\n",
      "2/2 - 1s - 291ms/step - loss: 0.0812 - val_loss: 0.1737\n",
      "Epoch 42/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.0803 - val_loss: 0.1613\n",
      "Epoch 43/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0793 - val_loss: 0.1616\n",
      "Epoch 44/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0790 - val_loss: 0.1713\n",
      "Epoch 45/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0779 - val_loss: 0.1728\n",
      "Epoch 46/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0771 - val_loss: 0.2028\n",
      "Epoch 47/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0770 - val_loss: 0.1852\n",
      "Epoch 48/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0793 - val_loss: 0.3135\n",
      "Epoch 49/100\n",
      "2/2 - 0s - 235ms/step - loss: 0.1033 - val_loss: 0.1471\n",
      "Epoch 50/100\n",
      "2/2 - 1s - 279ms/step - loss: 0.1138 - val_loss: 0.0754\n",
      "Epoch 51/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.1093 - val_loss: 0.0922\n",
      "Epoch 52/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0829 - val_loss: 0.2216\n",
      "Epoch 53/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0972 - val_loss: 0.1731\n",
      "Epoch 54/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.0801 - val_loss: 0.0673\n",
      "Epoch 55/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0870 - val_loss: 0.0623\n",
      "Epoch 56/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.0861 - val_loss: 0.0649\n",
      "Epoch 57/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0782 - val_loss: 0.1168\n",
      "Epoch 58/100\n",
      "2/2 - 1s - 258ms/step - loss: 0.0819 - val_loss: 0.1342\n",
      "Epoch 59/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.0800 - val_loss: 0.0945\n",
      "Epoch 60/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0762 - val_loss: 0.0635\n",
      "Epoch 61/100\n",
      "2/2 - 1s - 280ms/step - loss: 0.0798 - val_loss: 0.0670\n",
      "Epoch 62/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0754 - val_loss: 0.1073\n",
      "Epoch 63/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0767 - val_loss: 0.1349\n",
      "Epoch 64/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0759 - val_loss: 0.1133\n",
      "Epoch 65/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0723 - val_loss: 0.0836\n",
      "Epoch 66/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0740 - val_loss: 0.0857\n",
      "Epoch 67/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0720 - val_loss: 0.1207\n",
      "Epoch 68/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0727 - val_loss: 0.1373\n",
      "Epoch 69/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.0696 - val_loss: 0.1069\n",
      "Epoch 70/100\n",
      "2/2 - 0s - 225ms/step - loss: 0.0698 - val_loss: 0.0924\n",
      "Epoch 71/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0696 - val_loss: 0.1159\n",
      "Epoch 72/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0674 - val_loss: 0.1472\n",
      "Epoch 73/100\n",
      "2/2 - 0s - 228ms/step - loss: 0.0675 - val_loss: 0.1378\n",
      "Epoch 74/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.0648 - val_loss: 0.1114\n",
      "Epoch 75/100\n",
      "2/2 - 0s - 224ms/step - loss: 0.0661 - val_loss: 0.1252\n",
      "Epoch 76/100\n",
      "2/2 - 0s - 228ms/step - loss: 0.0648 - val_loss: 0.1635\n",
      "Epoch 77/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0674 - val_loss: 0.1496\n",
      "Epoch 78/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.0636 - val_loss: 0.1162\n",
      "Epoch 79/100\n",
      "2/2 - 0s - 225ms/step - loss: 0.0687 - val_loss: 0.1238\n",
      "Epoch 80/100\n",
      "2/2 - 0s - 226ms/step - loss: 0.0652 - val_loss: 0.1521\n",
      "Epoch 81/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0653 - val_loss: 0.1234\n",
      "Epoch 82/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0641 - val_loss: 0.1032\n",
      "Epoch 83/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0645 - val_loss: 0.1128\n",
      "Epoch 84/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0639 - val_loss: 0.1204\n",
      "Epoch 85/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.0630 - val_loss: 0.1066\n",
      "Epoch 86/100\n",
      "2/2 - 0s - 222ms/step - loss: 0.0633 - val_loss: 0.1065\n",
      "Epoch 87/100\n",
      "2/2 - 1s - 268ms/step - loss: 0.0631 - val_loss: 0.1201\n",
      "Epoch 88/100\n",
      "2/2 - 1s - 296ms/step - loss: 0.0634 - val_loss: 0.1248\n",
      "Epoch 89/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.0627 - val_loss: 0.1121\n",
      "Epoch 90/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0627 - val_loss: 0.1066\n",
      "Epoch 91/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0627 - val_loss: 0.1128\n",
      "Epoch 92/100\n",
      "2/2 - 1s - 257ms/step - loss: 0.0627 - val_loss: 0.1124\n",
      "Epoch 93/100\n",
      "2/2 - 1s - 274ms/step - loss: 0.0621 - val_loss: 0.0996\n",
      "Epoch 94/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0627 - val_loss: 0.0992\n",
      "Epoch 95/100\n",
      "2/2 - 0s - 221ms/step - loss: 0.0620 - val_loss: 0.1035\n",
      "Epoch 96/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.0619 - val_loss: 0.0993\n",
      "Epoch 97/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0617 - val_loss: 0.0988\n",
      "Epoch 98/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0615 - val_loss: 0.0971\n",
      "Epoch 99/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0614 - val_loss: 0.0995\n",
      "Epoch 100/100\n",
      "2/2 - 0s - 222ms/step - loss: 0.0614 - val_loss: 0.1011\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "未来20天预测汇率：\n",
      "[0.00532853 0.0053296  0.00533278 0.00533793 0.00534458 0.00535214\n",
      " 0.00536002 0.00536774 0.00537494 0.00538139 0.00538694 0.00539155\n",
      " 0.00539522 0.00539799 0.00539992 0.00540109 0.00540158 0.00540147\n",
      " 0.00540085 0.0053998 ]\n",
      "------------------------------\n",
      "预测 SGD 对人民币的汇率：\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rprp/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 5s - 2s/step - loss: 0.2423 - val_loss: 0.1492\n",
      "Epoch 2/100\n",
      "2/2 - 1s - 305ms/step - loss: 0.0849 - val_loss: 0.1818\n",
      "Epoch 3/100\n",
      "2/2 - 1s - 292ms/step - loss: 0.1320 - val_loss: 0.0973\n",
      "Epoch 4/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0954 - val_loss: 0.0507\n",
      "Epoch 5/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.0819 - val_loss: 0.0666\n",
      "Epoch 6/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.0820 - val_loss: 0.0640\n",
      "Epoch 7/100\n",
      "2/2 - 0s - 222ms/step - loss: 0.0753 - val_loss: 0.0508\n",
      "Epoch 8/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0690 - val_loss: 0.0498\n",
      "Epoch 9/100\n",
      "2/2 - 0s - 224ms/step - loss: 0.0710 - val_loss: 0.0577\n",
      "Epoch 10/100\n",
      "2/2 - 1s - 278ms/step - loss: 0.0760 - val_loss: 0.0547\n",
      "Epoch 11/100\n",
      "2/2 - 1s - 259ms/step - loss: 0.0749 - val_loss: 0.0471\n",
      "Epoch 12/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0716 - val_loss: 0.0463\n",
      "Epoch 13/100\n",
      "2/2 - 0s - 216ms/step - loss: 0.0706 - val_loss: 0.0488\n",
      "Epoch 14/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.0700 - val_loss: 0.0490\n",
      "Epoch 15/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0686 - val_loss: 0.0466\n",
      "Epoch 16/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.0667 - val_loss: 0.0437\n",
      "Epoch 17/100\n",
      "2/2 - 1s - 274ms/step - loss: 0.0658 - val_loss: 0.0452\n",
      "Epoch 18/100\n",
      "2/2 - 1s - 252ms/step - loss: 0.0664 - val_loss: 0.0477\n",
      "Epoch 19/100\n",
      "2/2 - 1s - 259ms/step - loss: 0.0675 - val_loss: 0.0469\n",
      "Epoch 20/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0673 - val_loss: 0.0440\n",
      "Epoch 21/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.0660 - val_loss: 0.0420\n",
      "Epoch 22/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0651 - val_loss: 0.0416\n",
      "Epoch 23/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0640 - val_loss: 0.0415\n",
      "Epoch 24/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.0629 - val_loss: 0.0410\n",
      "Epoch 25/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0619 - val_loss: 0.0417\n",
      "Epoch 26/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.0612 - val_loss: 0.0439\n",
      "Epoch 27/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0610 - val_loss: 0.0458\n",
      "Epoch 28/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.0610 - val_loss: 0.0452\n",
      "Epoch 29/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.0602 - val_loss: 0.0435\n",
      "Epoch 30/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.0591 - val_loss: 0.0438\n",
      "Epoch 31/100\n",
      "2/2 - 1s - 293ms/step - loss: 0.0576 - val_loss: 0.0467\n",
      "Epoch 32/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.0568 - val_loss: 0.0499\n",
      "Epoch 33/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0575 - val_loss: 0.0475\n",
      "Epoch 34/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0574 - val_loss: 0.0458\n",
      "Epoch 35/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0561 - val_loss: 0.0482\n",
      "Epoch 36/100\n",
      "2/2 - 1s - 261ms/step - loss: 0.0545 - val_loss: 0.0523\n",
      "Epoch 37/100\n",
      "2/2 - 1s - 261ms/step - loss: 0.0562 - val_loss: 0.0504\n",
      "Epoch 38/100\n",
      "2/2 - 1s - 258ms/step - loss: 0.0559 - val_loss: 0.0495\n",
      "Epoch 39/100\n",
      "2/2 - 1s - 258ms/step - loss: 0.0548 - val_loss: 0.0507\n",
      "Epoch 40/100\n",
      "2/2 - 1s - 263ms/step - loss: 0.0537 - val_loss: 0.0518\n",
      "Epoch 41/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.0551 - val_loss: 0.0507\n",
      "Epoch 42/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0548 - val_loss: 0.0523\n",
      "Epoch 43/100\n",
      "2/2 - 1s - 262ms/step - loss: 0.0537 - val_loss: 0.0522\n",
      "Epoch 44/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0529 - val_loss: 0.0515\n",
      "Epoch 45/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0533 - val_loss: 0.0522\n",
      "Epoch 46/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.0536 - val_loss: 0.0541\n",
      "Epoch 47/100\n",
      "2/2 - 0s - 224ms/step - loss: 0.0532 - val_loss: 0.0543\n",
      "Epoch 48/100\n",
      "2/2 - 0s - 233ms/step - loss: 0.0526 - val_loss: 0.0550\n",
      "Epoch 49/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.0532 - val_loss: 0.0564\n",
      "Epoch 50/100\n",
      "2/2 - 0s - 226ms/step - loss: 0.0525 - val_loss: 0.0570\n",
      "Epoch 51/100\n",
      "2/2 - 1s - 510ms/step - loss: 0.0526 - val_loss: 0.0580\n",
      "Epoch 52/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0526 - val_loss: 0.0596\n",
      "Epoch 53/100\n",
      "2/2 - 0s - 228ms/step - loss: 0.0526 - val_loss: 0.0590\n",
      "Epoch 54/100\n",
      "2/2 - 1s - 258ms/step - loss: 0.0522 - val_loss: 0.0587\n",
      "Epoch 55/100\n",
      "2/2 - 1s - 252ms/step - loss: 0.0528 - val_loss: 0.0619\n",
      "Epoch 56/100\n",
      "2/2 - 1s - 256ms/step - loss: 0.0525 - val_loss: 0.0589\n",
      "Epoch 57/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.0518 - val_loss: 0.0571\n",
      "Epoch 58/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0532 - val_loss: 0.0604\n",
      "Epoch 59/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0525 - val_loss: 0.0594\n",
      "Epoch 60/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.0509 - val_loss: 0.0556\n",
      "Epoch 61/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0525 - val_loss: 0.0573\n",
      "Epoch 62/100\n",
      "2/2 - 0s - 235ms/step - loss: 0.0522 - val_loss: 0.0615\n",
      "Epoch 63/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.0509 - val_loss: 0.0579\n",
      "Epoch 64/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0505 - val_loss: 0.0558\n",
      "Epoch 65/100\n",
      "2/2 - 0s - 224ms/step - loss: 0.0513 - val_loss: 0.0586\n",
      "Epoch 66/100\n",
      "2/2 - 0s - 223ms/step - loss: 0.0502 - val_loss: 0.0591\n",
      "Epoch 67/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.0500 - val_loss: 0.0541\n",
      "Epoch 68/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.0511 - val_loss: 0.0583\n",
      "Epoch 69/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0506 - val_loss: 0.0525\n",
      "Epoch 70/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0505 - val_loss: 0.0529\n",
      "Epoch 71/100\n",
      "2/2 - 0s - 218ms/step - loss: 0.0507 - val_loss: 0.0535\n",
      "Epoch 72/100\n",
      "2/2 - 1s - 341ms/step - loss: 0.0495 - val_loss: 0.0522\n",
      "Epoch 73/100\n",
      "2/2 - 1s - 253ms/step - loss: 0.0495 - val_loss: 0.0539\n",
      "Epoch 74/100\n",
      "2/2 - 0s - 221ms/step - loss: 0.0493 - val_loss: 0.0525\n",
      "Epoch 75/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.0494 - val_loss: 0.0508\n",
      "Epoch 76/100\n",
      "2/2 - 1s - 252ms/step - loss: 0.0502 - val_loss: 0.0561\n",
      "Epoch 77/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0508 - val_loss: 0.0505\n",
      "Epoch 78/100\n",
      "2/2 - 0s - 223ms/step - loss: 0.0495 - val_loss: 0.0496\n",
      "Epoch 79/100\n",
      "2/2 - 0s - 228ms/step - loss: 0.0504 - val_loss: 0.0497\n",
      "Epoch 80/100\n",
      "2/2 - 0s - 233ms/step - loss: 0.0496 - val_loss: 0.0501\n",
      "Epoch 81/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.0495 - val_loss: 0.0516\n",
      "Epoch 82/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.0488 - val_loss: 0.0514\n",
      "Epoch 83/100\n",
      "2/2 - 0s - 220ms/step - loss: 0.0490 - val_loss: 0.0499\n",
      "Epoch 84/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.0499 - val_loss: 0.0517\n",
      "Epoch 85/100\n",
      "2/2 - 1s - 256ms/step - loss: 0.0500 - val_loss: 0.0492\n",
      "Epoch 86/100\n",
      "2/2 - 0s - 225ms/step - loss: 0.0489 - val_loss: 0.0484\n",
      "Epoch 87/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.0492 - val_loss: 0.0492\n",
      "Epoch 88/100\n",
      "2/2 - 1s - 250ms/step - loss: 0.0485 - val_loss: 0.0475\n",
      "Epoch 89/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0489 - val_loss: 0.0479\n",
      "Epoch 90/100\n",
      "2/2 - 1s - 282ms/step - loss: 0.0483 - val_loss: 0.0472\n",
      "Epoch 91/100\n",
      "2/2 - 1s - 269ms/step - loss: 0.0482 - val_loss: 0.0469\n",
      "Epoch 92/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0481 - val_loss: 0.0467\n",
      "Epoch 93/100\n",
      "2/2 - 1s - 257ms/step - loss: 0.0480 - val_loss: 0.0459\n",
      "Epoch 94/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0488 - val_loss: 0.0466\n",
      "Epoch 95/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.0482 - val_loss: 0.0458\n",
      "Epoch 96/100\n",
      "2/2 - 0s - 222ms/step - loss: 0.0480 - val_loss: 0.0459\n",
      "Epoch 97/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0480 - val_loss: 0.0454\n",
      "Epoch 98/100\n",
      "2/2 - 1s - 262ms/step - loss: 0.0485 - val_loss: 0.0463\n",
      "Epoch 99/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0509 - val_loss: 0.0441\n",
      "Epoch 100/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0490 - val_loss: 0.0438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "未来20天预测汇率：\n",
      "[5.4026527 5.402028  5.4015427 5.401255  5.401149  5.401178  5.401303\n",
      " 5.401484  5.4016976 5.4019265 5.4021554 5.4023805 5.4025927 5.4027853\n",
      " 5.40297   5.403139  5.403295  5.403441  5.4035735 5.403697 ]\n",
      "------------------------------\n",
      "预测 THB 对人民币的汇率：\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rprp/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 5s - 2s/step - loss: 0.5515 - val_loss: 0.1082\n",
      "Epoch 2/100\n",
      "2/2 - 1s - 261ms/step - loss: 0.3031 - val_loss: 0.2260\n",
      "Epoch 3/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.1381 - val_loss: 0.3816\n",
      "Epoch 4/100\n",
      "2/2 - 1s - 509ms/step - loss: 0.1559 - val_loss: 0.1700\n",
      "Epoch 5/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.1089 - val_loss: 0.1190\n",
      "Epoch 6/100\n",
      "2/2 - 0s - 216ms/step - loss: 0.1429 - val_loss: 0.1369\n",
      "Epoch 7/100\n",
      "2/2 - 0s - 204ms/step - loss: 0.1061 - val_loss: 0.2093\n",
      "Epoch 8/100\n",
      "2/2 - 0s - 222ms/step - loss: 0.0739 - val_loss: 0.2889\n",
      "Epoch 9/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.1015 - val_loss: 0.2748\n",
      "Epoch 10/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0840 - val_loss: 0.2139\n",
      "Epoch 11/100\n",
      "2/2 - 0s - 220ms/step - loss: 0.0750 - val_loss: 0.1775\n",
      "Epoch 12/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0858 - val_loss: 0.1777\n",
      "Epoch 13/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0820 - val_loss: 0.2055\n",
      "Epoch 14/100\n",
      "2/2 - 1s - 264ms/step - loss: 0.0705 - val_loss: 0.2451\n",
      "Epoch 15/100\n",
      "2/2 - 1s - 279ms/step - loss: 0.0753 - val_loss: 0.2583\n",
      "Epoch 16/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.0778 - val_loss: 0.2368\n",
      "Epoch 17/100\n",
      "2/2 - 0s - 226ms/step - loss: 0.0696 - val_loss: 0.2093\n",
      "Epoch 18/100\n",
      "2/2 - 0s - 221ms/step - loss: 0.0725 - val_loss: 0.2009\n",
      "Epoch 19/100\n",
      "2/2 - 0s - 227ms/step - loss: 0.0731 - val_loss: 0.2135\n",
      "Epoch 20/100\n",
      "2/2 - 0s - 226ms/step - loss: 0.0692 - val_loss: 0.2335\n",
      "Epoch 21/100\n",
      "2/2 - 0s - 227ms/step - loss: 0.0702 - val_loss: 0.2395\n",
      "Epoch 22/100\n",
      "2/2 - 1s - 261ms/step - loss: 0.0703 - val_loss: 0.2235\n",
      "Epoch 23/100\n",
      "2/2 - 1s - 259ms/step - loss: 0.0686 - val_loss: 0.2115\n",
      "Epoch 24/100\n",
      "2/2 - 1s - 291ms/step - loss: 0.0699 - val_loss: 0.2158\n",
      "Epoch 25/100\n",
      "2/2 - 1s - 271ms/step - loss: 0.0686 - val_loss: 0.2281\n",
      "Epoch 26/100\n",
      "2/2 - 1s - 262ms/step - loss: 0.0687 - val_loss: 0.2287\n",
      "Epoch 27/100\n",
      "2/2 - 1s - 264ms/step - loss: 0.0684 - val_loss: 0.2192\n",
      "Epoch 28/100\n",
      "2/2 - 1s - 257ms/step - loss: 0.0682 - val_loss: 0.2159\n",
      "Epoch 29/100\n",
      "2/2 - 1s - 264ms/step - loss: 0.0683 - val_loss: 0.2200\n",
      "Epoch 30/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0679 - val_loss: 0.2247\n",
      "Epoch 31/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.0680 - val_loss: 0.2205\n",
      "Epoch 32/100\n",
      "2/2 - 1s - 256ms/step - loss: 0.0677 - val_loss: 0.2169\n",
      "Epoch 33/100\n",
      "2/2 - 1s - 256ms/step - loss: 0.0678 - val_loss: 0.2168\n",
      "Epoch 34/100\n",
      "2/2 - 1s - 272ms/step - loss: 0.0677 - val_loss: 0.2183\n",
      "Epoch 35/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0676 - val_loss: 0.2209\n",
      "Epoch 36/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.0676 - val_loss: 0.2166\n",
      "Epoch 37/100\n",
      "2/2 - 1s - 266ms/step - loss: 0.0674 - val_loss: 0.2129\n",
      "Epoch 38/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.0675 - val_loss: 0.2147\n",
      "Epoch 39/100\n",
      "2/2 - 1s - 258ms/step - loss: 0.0673 - val_loss: 0.2185\n",
      "Epoch 40/100\n",
      "2/2 - 1s - 258ms/step - loss: 0.0673 - val_loss: 0.2137\n",
      "Epoch 41/100\n",
      "2/2 - 1s - 253ms/step - loss: 0.0672 - val_loss: 0.2107\n",
      "Epoch 42/100\n",
      "2/2 - 1s - 256ms/step - loss: 0.0672 - val_loss: 0.2142\n",
      "Epoch 43/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0670 - val_loss: 0.2141\n",
      "Epoch 44/100\n",
      "2/2 - 1s - 257ms/step - loss: 0.0669 - val_loss: 0.2102\n",
      "Epoch 45/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0669 - val_loss: 0.2114\n",
      "Epoch 46/100\n",
      "2/2 - 1s - 259ms/step - loss: 0.0668 - val_loss: 0.2130\n",
      "Epoch 47/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0668 - val_loss: 0.2086\n",
      "Epoch 48/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0668 - val_loss: 0.2087\n",
      "Epoch 49/100\n",
      "2/2 - 1s - 260ms/step - loss: 0.0666 - val_loss: 0.2122\n",
      "Epoch 50/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0666 - val_loss: 0.2073\n",
      "Epoch 51/100\n",
      "2/2 - 1s - 350ms/step - loss: 0.0665 - val_loss: 0.2061\n",
      "Epoch 52/100\n",
      "2/2 - 1s - 280ms/step - loss: 0.0664 - val_loss: 0.2099\n",
      "Epoch 53/100\n",
      "2/2 - 1s - 266ms/step - loss: 0.0664 - val_loss: 0.2064\n",
      "Epoch 54/100\n",
      "2/2 - 1s - 253ms/step - loss: 0.0663 - val_loss: 0.2031\n",
      "Epoch 55/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.0664 - val_loss: 0.2061\n",
      "Epoch 56/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0661 - val_loss: 0.2082\n",
      "Epoch 57/100\n",
      "2/2 - 1s - 302ms/step - loss: 0.0661 - val_loss: 0.2056\n",
      "Epoch 58/100\n",
      "2/2 - 1s - 265ms/step - loss: 0.0660 - val_loss: 0.2053\n",
      "Epoch 59/100\n",
      "2/2 - 1s - 262ms/step - loss: 0.0659 - val_loss: 0.2069\n",
      "Epoch 60/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.0658 - val_loss: 0.2034\n",
      "Epoch 61/100\n",
      "2/2 - 0s - 222ms/step - loss: 0.0658 - val_loss: 0.2023\n",
      "Epoch 62/100\n",
      "2/2 - 0s - 222ms/step - loss: 0.0657 - val_loss: 0.2055\n",
      "Epoch 63/100\n",
      "2/2 - 0s - 233ms/step - loss: 0.0657 - val_loss: 0.2040\n",
      "Epoch 64/100\n",
      "2/2 - 0s - 250ms/step - loss: 0.0655 - val_loss: 0.2012\n",
      "Epoch 65/100\n",
      "2/2 - 0s - 219ms/step - loss: 0.0655 - val_loss: 0.2032\n",
      "Epoch 66/100\n",
      "2/2 - 0s - 228ms/step - loss: 0.0654 - val_loss: 0.2028\n",
      "Epoch 67/100\n",
      "2/2 - 1s - 266ms/step - loss: 0.0652 - val_loss: 0.2007\n",
      "Epoch 68/100\n",
      "2/2 - 1s - 555ms/step - loss: 0.0652 - val_loss: 0.2022\n",
      "Epoch 69/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0650 - val_loss: 0.1992\n",
      "Epoch 70/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0650 - val_loss: 0.2021\n",
      "Epoch 71/100\n",
      "2/2 - 0s - 225ms/step - loss: 0.0649 - val_loss: 0.1973\n",
      "Epoch 72/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.0649 - val_loss: 0.1980\n",
      "Epoch 73/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0649 - val_loss: 0.1998\n",
      "Epoch 74/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0645 - val_loss: 0.1943\n",
      "Epoch 75/100\n",
      "2/2 - 1s - 264ms/step - loss: 0.0647 - val_loss: 0.1972\n",
      "Epoch 76/100\n",
      "2/2 - 1s - 281ms/step - loss: 0.0645 - val_loss: 0.1972\n",
      "Epoch 77/100\n",
      "2/2 - 1s - 265ms/step - loss: 0.0642 - val_loss: 0.1922\n",
      "Epoch 78/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.0644 - val_loss: 0.1951\n",
      "Epoch 79/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0641 - val_loss: 0.1934\n",
      "Epoch 80/100\n",
      "2/2 - 1s - 268ms/step - loss: 0.0640 - val_loss: 0.1912\n",
      "Epoch 81/100\n",
      "2/2 - 1s - 252ms/step - loss: 0.0641 - val_loss: 0.1954\n",
      "Epoch 82/100\n",
      "2/2 - 0s - 226ms/step - loss: 0.0639 - val_loss: 0.1888\n",
      "Epoch 83/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.0640 - val_loss: 0.1913\n",
      "Epoch 84/100\n",
      "2/2 - 0s - 235ms/step - loss: 0.0638 - val_loss: 0.1917\n",
      "Epoch 85/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0635 - val_loss: 0.1832\n",
      "Epoch 86/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0641 - val_loss: 0.1896\n",
      "Epoch 87/100\n",
      "2/2 - 0s - 227ms/step - loss: 0.0638 - val_loss: 0.1935\n",
      "Epoch 88/100\n",
      "2/2 - 0s - 222ms/step - loss: 0.0634 - val_loss: 0.1803\n",
      "Epoch 89/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0641 - val_loss: 0.1817\n",
      "Epoch 90/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0640 - val_loss: 0.1925\n",
      "Epoch 91/100\n",
      "2/2 - 1s - 287ms/step - loss: 0.0632 - val_loss: 0.1811\n",
      "Epoch 92/100\n",
      "2/2 - 1s - 273ms/step - loss: 0.0635 - val_loss: 0.1826\n",
      "Epoch 93/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0636 - val_loss: 0.1921\n",
      "Epoch 94/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0629 - val_loss: 0.1774\n",
      "Epoch 95/100\n",
      "2/2 - 1s - 258ms/step - loss: 0.0635 - val_loss: 0.1781\n",
      "Epoch 96/100\n",
      "2/2 - 1s - 311ms/step - loss: 0.0637 - val_loss: 0.1888\n",
      "Epoch 97/100\n",
      "2/2 - 1s - 278ms/step - loss: 0.0628 - val_loss: 0.1782\n",
      "Epoch 98/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.0628 - val_loss: 0.1756\n",
      "Epoch 99/100\n",
      "2/2 - 1s - 274ms/step - loss: 0.0632 - val_loss: 0.1856\n",
      "Epoch 100/100\n",
      "2/2 - 1s - 268ms/step - loss: 0.0628 - val_loss: 0.1794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "未来20天预测汇率：\n",
      "[0.20469421 0.20467311 0.20475407 0.20493454 0.2051972  0.20551999\n",
      " 0.20588148 0.20626356 0.20665231 0.20703784 0.20741352 0.20777537\n",
      " 0.2081211  0.20844968 0.20876075 0.20905441 0.20933092 0.20959069\n",
      " 0.20983414 0.21006176]\n",
      "------------------------------\n",
      "预测 HKD 对人民币的汇率：\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rprp/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 6s - 3s/step - loss: 0.4856 - val_loss: 0.2518\n",
      "Epoch 2/100\n",
      "2/2 - 1s - 274ms/step - loss: 0.2970 - val_loss: 0.1135\n",
      "Epoch 3/100\n",
      "2/2 - 1s - 290ms/step - loss: 0.2126 - val_loss: 0.0515\n",
      "Epoch 4/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.1653 - val_loss: 0.0638\n",
      "Epoch 5/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.1295 - val_loss: 0.1059\n",
      "Epoch 6/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.1474 - val_loss: 0.1217\n",
      "Epoch 7/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.1585 - val_loss: 0.1171\n",
      "Epoch 8/100\n",
      "2/2 - 1s - 277ms/step - loss: 0.1541 - val_loss: 0.0974\n",
      "Epoch 9/100\n",
      "2/2 - 1s - 258ms/step - loss: 0.1395 - val_loss: 0.0698\n",
      "Epoch 10/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.1285 - val_loss: 0.0661\n",
      "Epoch 11/100\n",
      "2/2 - 1s - 265ms/step - loss: 0.1213 - val_loss: 0.0839\n",
      "Epoch 12/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.1088 - val_loss: 0.1126\n",
      "Epoch 13/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.1174 - val_loss: 0.1203\n",
      "Epoch 14/100\n",
      "2/2 - 1s - 508ms/step - loss: 0.1212 - val_loss: 0.1107\n",
      "Epoch 15/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.1116 - val_loss: 0.0970\n",
      "Epoch 16/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.1053 - val_loss: 0.1028\n",
      "Epoch 17/100\n",
      "2/2 - 0s - 243ms/step - loss: 0.0967 - val_loss: 0.1244\n",
      "Epoch 18/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0967 - val_loss: 0.1335\n",
      "Epoch 19/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0994 - val_loss: 0.1266\n",
      "Epoch 20/100\n",
      "2/2 - 0s - 235ms/step - loss: 0.0922 - val_loss: 0.1250\n",
      "Epoch 21/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0879 - val_loss: 0.1389\n",
      "Epoch 22/100\n",
      "2/2 - 0s - 233ms/step - loss: 0.0874 - val_loss: 0.1444\n",
      "Epoch 23/100\n",
      "2/2 - 1s - 265ms/step - loss: 0.0885 - val_loss: 0.1379\n",
      "Epoch 24/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0855 - val_loss: 0.1367\n",
      "Epoch 25/100\n",
      "2/2 - 1s - 282ms/step - loss: 0.0838 - val_loss: 0.1474\n",
      "Epoch 26/100\n",
      "2/2 - 1s - 283ms/step - loss: 0.0855 - val_loss: 0.1476\n",
      "Epoch 27/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0866 - val_loss: 0.1360\n",
      "Epoch 28/100\n",
      "2/2 - 1s - 324ms/step - loss: 0.0834 - val_loss: 0.1385\n",
      "Epoch 29/100\n",
      "2/2 - 1s - 265ms/step - loss: 0.0836 - val_loss: 0.1333\n",
      "Epoch 30/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0828 - val_loss: 0.1302\n",
      "Epoch 31/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0821 - val_loss: 0.1292\n",
      "Epoch 32/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0824 - val_loss: 0.1225\n",
      "Epoch 33/100\n",
      "2/2 - 1s - 284ms/step - loss: 0.0807 - val_loss: 0.1252\n",
      "Epoch 34/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.0818 - val_loss: 0.1180\n",
      "Epoch 35/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0805 - val_loss: 0.1128\n",
      "Epoch 36/100\n",
      "2/2 - 0s - 212ms/step - loss: 0.0786 - val_loss: 0.1199\n",
      "Epoch 37/100\n",
      "2/2 - 0s - 202ms/step - loss: 0.0822 - val_loss: 0.1089\n",
      "Epoch 38/100\n",
      "2/2 - 1s - 257ms/step - loss: 0.0798 - val_loss: 0.1006\n",
      "Epoch 39/100\n",
      "2/2 - 0s - 250ms/step - loss: 0.0780 - val_loss: 0.1182\n",
      "Epoch 40/100\n",
      "2/2 - 1s - 276ms/step - loss: 0.0852 - val_loss: 0.1057\n",
      "Epoch 41/100\n",
      "2/2 - 1s - 299ms/step - loss: 0.0802 - val_loss: 0.0904\n",
      "Epoch 42/100\n",
      "2/2 - 1s - 277ms/step - loss: 0.0817 - val_loss: 0.1082\n",
      "Epoch 43/100\n",
      "2/2 - 1s - 256ms/step - loss: 0.0783 - val_loss: 0.1091\n",
      "Epoch 44/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0822 - val_loss: 0.0878\n",
      "Epoch 45/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0824 - val_loss: 0.0987\n",
      "Epoch 46/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0740 - val_loss: 0.1165\n",
      "Epoch 47/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.0875 - val_loss: 0.0963\n",
      "Epoch 48/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.0764 - val_loss: 0.0931\n",
      "Epoch 49/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0744 - val_loss: 0.1145\n",
      "Epoch 50/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.0853 - val_loss: 0.0982\n",
      "Epoch 51/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0767 - val_loss: 0.0849\n",
      "Epoch 52/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0794 - val_loss: 0.1028\n",
      "Epoch 53/100\n",
      "2/2 - 0s - 233ms/step - loss: 0.0748 - val_loss: 0.1054\n",
      "Epoch 54/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0785 - val_loss: 0.0859\n",
      "Epoch 55/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.0780 - val_loss: 0.0950\n",
      "Epoch 56/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.0718 - val_loss: 0.1109\n",
      "Epoch 57/100\n",
      "2/2 - 1s - 279ms/step - loss: 0.0823 - val_loss: 0.0912\n",
      "Epoch 58/100\n",
      "2/2 - 1s - 281ms/step - loss: 0.0737 - val_loss: 0.0916\n",
      "Epoch 59/100\n",
      "2/2 - 1s - 314ms/step - loss: 0.0717 - val_loss: 0.1029\n",
      "Epoch 60/100\n",
      "2/2 - 1s - 252ms/step - loss: 0.0769 - val_loss: 0.0875\n",
      "Epoch 61/100\n",
      "2/2 - 1s - 253ms/step - loss: 0.0727 - val_loss: 0.0934\n",
      "Epoch 62/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0716 - val_loss: 0.0931\n",
      "Epoch 63/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0723 - val_loss: 0.0851\n",
      "Epoch 64/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0709 - val_loss: 0.0947\n",
      "Epoch 65/100\n",
      "2/2 - 1s - 276ms/step - loss: 0.0738 - val_loss: 0.0816\n",
      "Epoch 66/100\n",
      "2/2 - 1s - 266ms/step - loss: 0.0711 - val_loss: 0.0890\n",
      "Epoch 67/100\n",
      "2/2 - 1s - 277ms/step - loss: 0.0710 - val_loss: 0.0847\n",
      "Epoch 68/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.0699 - val_loss: 0.0835\n",
      "Epoch 69/100\n",
      "2/2 - 1s - 265ms/step - loss: 0.0693 - val_loss: 0.0854\n",
      "Epoch 70/100\n",
      "2/2 - 1s - 263ms/step - loss: 0.0707 - val_loss: 0.0766\n",
      "Epoch 71/100\n",
      "2/2 - 1s - 268ms/step - loss: 0.0692 - val_loss: 0.0845\n",
      "Epoch 72/100\n",
      "2/2 - 1s - 253ms/step - loss: 0.0710 - val_loss: 0.0733\n",
      "Epoch 73/100\n",
      "2/2 - 1s - 250ms/step - loss: 0.0693 - val_loss: 0.0822\n",
      "Epoch 74/100\n",
      "2/2 - 1s - 258ms/step - loss: 0.0701 - val_loss: 0.0733\n",
      "Epoch 75/100\n",
      "2/2 - 1s - 272ms/step - loss: 0.0681 - val_loss: 0.0785\n",
      "Epoch 76/100\n",
      "2/2 - 1s - 319ms/step - loss: 0.0687 - val_loss: 0.0718\n",
      "Epoch 77/100\n",
      "2/2 - 1s - 494ms/step - loss: 0.0673 - val_loss: 0.0785\n",
      "Epoch 78/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0697 - val_loss: 0.0662\n",
      "Epoch 79/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0691 - val_loss: 0.0774\n",
      "Epoch 80/100\n",
      "2/2 - 1s - 257ms/step - loss: 0.0690 - val_loss: 0.0685\n",
      "Epoch 81/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0665 - val_loss: 0.0759\n",
      "Epoch 82/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0680 - val_loss: 0.0670\n",
      "Epoch 83/100\n",
      "2/2 - 1s - 261ms/step - loss: 0.0662 - val_loss: 0.0762\n",
      "Epoch 84/100\n",
      "2/2 - 1s - 266ms/step - loss: 0.0685 - val_loss: 0.0651\n",
      "Epoch 85/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0662 - val_loss: 0.0768\n",
      "Epoch 86/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0684 - val_loss: 0.0671\n",
      "Epoch 87/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.0648 - val_loss: 0.0726\n",
      "Epoch 88/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0651 - val_loss: 0.0682\n",
      "Epoch 89/100\n",
      "2/2 - 1s - 358ms/step - loss: 0.0639 - val_loss: 0.0707\n",
      "Epoch 90/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0640 - val_loss: 0.0673\n",
      "Epoch 91/100\n",
      "2/2 - 1s - 268ms/step - loss: 0.0629 - val_loss: 0.0704\n",
      "Epoch 92/100\n",
      "2/2 - 1s - 261ms/step - loss: 0.0645 - val_loss: 0.0617\n",
      "Epoch 93/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0624 - val_loss: 0.0745\n",
      "Epoch 94/100\n",
      "2/2 - 1s - 267ms/step - loss: 0.0695 - val_loss: 0.0613\n",
      "Epoch 95/100\n",
      "2/2 - 1s - 262ms/step - loss: 0.0621 - val_loss: 0.0683\n",
      "Epoch 96/100\n",
      "2/2 - 1s - 257ms/step - loss: 0.0626 - val_loss: 0.0648\n",
      "Epoch 97/100\n",
      "2/2 - 1s - 261ms/step - loss: 0.0606 - val_loss: 0.0711\n",
      "Epoch 98/100\n",
      "2/2 - 1s - 252ms/step - loss: 0.0612 - val_loss: 0.0692\n",
      "Epoch 99/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0604 - val_loss: 0.0654\n",
      "Epoch 100/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0589 - val_loss: 0.0841\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "未来20天预测汇率：\n",
      "[0.9277548  0.9277751  0.9276609  0.92740554 0.927035   0.92658615\n",
      " 0.92609334 0.9255826  0.92507005 0.9245635  0.92406505 0.92357314\n",
      " 0.9230852  0.9225983  0.9221104  0.9216203  0.9211277  0.9206331\n",
      " 0.9201376  0.91964257]\n",
      "------------------------------\n",
      "预测 MYR 对人民币的汇率：\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rprp/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 4s - 2s/step - loss: 0.4988 - val_loss: 0.1896\n",
      "Epoch 2/100\n",
      "2/2 - 1s - 281ms/step - loss: 0.3284 - val_loss: 0.1393\n",
      "Epoch 3/100\n",
      "2/2 - 1s - 290ms/step - loss: 0.1057 - val_loss: 0.4369\n",
      "Epoch 4/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.1862 - val_loss: 0.1952\n",
      "Epoch 5/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.0941 - val_loss: 0.1262\n",
      "Epoch 6/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.1375 - val_loss: 0.1278\n",
      "Epoch 7/100\n",
      "2/2 - 0s - 203ms/step - loss: 0.1098 - val_loss: 0.1654\n",
      "Epoch 8/100\n",
      "2/2 - 0s - 190ms/step - loss: 0.0603 - val_loss: 0.2542\n",
      "Epoch 9/100\n",
      "2/2 - 0s - 195ms/step - loss: 0.0909 - val_loss: 0.2697\n",
      "Epoch 10/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0983 - val_loss: 0.2251\n",
      "Epoch 11/100\n",
      "2/2 - 1s - 282ms/step - loss: 0.0791 - val_loss: 0.1685\n",
      "Epoch 12/100\n",
      "2/2 - 1s - 275ms/step - loss: 0.0726 - val_loss: 0.1446\n",
      "Epoch 13/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0777 - val_loss: 0.1488\n",
      "Epoch 14/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0698 - val_loss: 0.1736\n",
      "Epoch 15/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0633 - val_loss: 0.2014\n",
      "Epoch 16/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.0688 - val_loss: 0.2137\n",
      "Epoch 17/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.0734 - val_loss: 0.2027\n",
      "Epoch 18/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0709 - val_loss: 0.1805\n",
      "Epoch 19/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0686 - val_loss: 0.1636\n",
      "Epoch 20/100\n",
      "2/2 - 1s - 252ms/step - loss: 0.0678 - val_loss: 0.1614\n",
      "Epoch 21/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.0662 - val_loss: 0.1710\n",
      "Epoch 22/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.0644 - val_loss: 0.1843\n",
      "Epoch 23/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0656 - val_loss: 0.1921\n",
      "Epoch 24/100\n",
      "2/2 - 1s - 253ms/step - loss: 0.0677 - val_loss: 0.1888\n",
      "Epoch 25/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0676 - val_loss: 0.1787\n",
      "Epoch 26/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0670 - val_loss: 0.1693\n",
      "Epoch 27/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0664 - val_loss: 0.1662\n",
      "Epoch 28/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0653 - val_loss: 0.1707\n",
      "Epoch 29/100\n",
      "2/2 - 1s - 523ms/step - loss: 0.0646 - val_loss: 0.1790\n",
      "Epoch 30/100\n",
      "2/2 - 1s - 265ms/step - loss: 0.0652 - val_loss: 0.1848\n",
      "Epoch 31/100\n",
      "2/2 - 1s - 309ms/step - loss: 0.0664 - val_loss: 0.1841\n",
      "Epoch 32/100\n",
      "2/2 - 1s - 280ms/step - loss: 0.0667 - val_loss: 0.1782\n",
      "Epoch 33/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0663 - val_loss: 0.1701\n",
      "Epoch 34/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.0659 - val_loss: 0.1656\n",
      "Epoch 35/100\n",
      "2/2 - 1s - 257ms/step - loss: 0.0652 - val_loss: 0.1671\n",
      "Epoch 36/100\n",
      "2/2 - 1s - 267ms/step - loss: 0.0644 - val_loss: 0.1712\n",
      "Epoch 37/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.0646 - val_loss: 0.1743\n",
      "Epoch 38/100\n",
      "2/2 - 0s - 235ms/step - loss: 0.0652 - val_loss: 0.1732\n",
      "Epoch 39/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0654 - val_loss: 0.1688\n",
      "Epoch 40/100\n",
      "2/2 - 0s - 228ms/step - loss: 0.0651 - val_loss: 0.1656\n",
      "Epoch 41/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0648 - val_loss: 0.1647\n",
      "Epoch 42/100\n",
      "2/2 - 1s - 258ms/step - loss: 0.0645 - val_loss: 0.1656\n",
      "Epoch 43/100\n",
      "2/2 - 0s - 233ms/step - loss: 0.0643 - val_loss: 0.1680\n",
      "Epoch 44/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.0643 - val_loss: 0.1703\n",
      "Epoch 45/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0647 - val_loss: 0.1696\n",
      "Epoch 46/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.0648 - val_loss: 0.1666\n",
      "Epoch 47/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0647 - val_loss: 0.1637\n",
      "Epoch 48/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0645 - val_loss: 0.1624\n",
      "Epoch 49/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0642 - val_loss: 0.1632\n",
      "Epoch 50/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0640 - val_loss: 0.1648\n",
      "Epoch 51/100\n",
      "2/2 - 1s - 269ms/step - loss: 0.0640 - val_loss: 0.1664\n",
      "Epoch 52/100\n",
      "2/2 - 1s - 253ms/step - loss: 0.0642 - val_loss: 0.1658\n",
      "Epoch 53/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0644 - val_loss: 0.1635\n",
      "Epoch 54/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0642 - val_loss: 0.1619\n",
      "Epoch 55/100\n",
      "2/2 - 1s - 252ms/step - loss: 0.0640 - val_loss: 0.1609\n",
      "Epoch 56/100\n",
      "2/2 - 1s - 262ms/step - loss: 0.0639 - val_loss: 0.1604\n",
      "Epoch 57/100\n",
      "2/2 - 1s - 271ms/step - loss: 0.0638 - val_loss: 0.1602\n",
      "Epoch 58/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0637 - val_loss: 0.1603\n",
      "Epoch 59/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.0636 - val_loss: 0.1607\n",
      "Epoch 60/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0637 - val_loss: 0.1599\n",
      "Epoch 61/100\n",
      "2/2 - 1s - 328ms/step - loss: 0.0638 - val_loss: 0.1582\n",
      "Epoch 62/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.0636 - val_loss: 0.1572\n",
      "Epoch 63/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0634 - val_loss: 0.1566\n",
      "Epoch 64/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0633 - val_loss: 0.1563\n",
      "Epoch 65/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.0632 - val_loss: 0.1564\n",
      "Epoch 66/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0631 - val_loss: 0.1568\n",
      "Epoch 67/100\n",
      "2/2 - 1s - 267ms/step - loss: 0.0633 - val_loss: 0.1560\n",
      "Epoch 68/100\n",
      "2/2 - 1s - 253ms/step - loss: 0.0633 - val_loss: 0.1542\n",
      "Epoch 69/100\n",
      "2/2 - 0s - 231ms/step - loss: 0.0630 - val_loss: 0.1531\n",
      "Epoch 70/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.0629 - val_loss: 0.1525\n",
      "Epoch 71/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0628 - val_loss: 0.1522\n",
      "Epoch 72/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.0626 - val_loss: 0.1523\n",
      "Epoch 73/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.0627 - val_loss: 0.1513\n",
      "Epoch 74/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0627 - val_loss: 0.1493\n",
      "Epoch 75/100\n",
      "2/2 - 1s - 253ms/step - loss: 0.0624 - val_loss: 0.1502\n",
      "Epoch 76/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0623 - val_loss: 0.1506\n",
      "Epoch 77/100\n",
      "2/2 - 1s - 273ms/step - loss: 0.0624 - val_loss: 0.1498\n",
      "Epoch 78/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.0624 - val_loss: 0.1480\n",
      "Epoch 79/100\n",
      "2/2 - 1s - 323ms/step - loss: 0.0622 - val_loss: 0.1476\n",
      "Epoch 80/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.0619 - val_loss: 0.1484\n",
      "Epoch 81/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.0620 - val_loss: 0.1479\n",
      "Epoch 82/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.0621 - val_loss: 0.1463\n",
      "Epoch 83/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.0618 - val_loss: 0.1461\n",
      "Epoch 84/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.0617 - val_loss: 0.1457\n",
      "Epoch 85/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.0617 - val_loss: 0.1450\n",
      "Epoch 86/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.0615 - val_loss: 0.1450\n",
      "Epoch 87/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.0614 - val_loss: 0.1446\n",
      "Epoch 88/100\n",
      "2/2 - 1s - 274ms/step - loss: 0.0615 - val_loss: 0.1440\n",
      "Epoch 89/100\n",
      "2/2 - 1s - 312ms/step - loss: 0.0613 - val_loss: 0.1431\n",
      "Epoch 90/100\n",
      "2/2 - 1s - 262ms/step - loss: 0.0613 - val_loss: 0.1421\n",
      "Epoch 91/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.0610 - val_loss: 0.1418\n",
      "Epoch 92/100\n",
      "2/2 - 0s - 235ms/step - loss: 0.0608 - val_loss: 0.1422\n",
      "Epoch 93/100\n",
      "2/2 - 1s - 511ms/step - loss: 0.0607 - val_loss: 0.1421\n",
      "Epoch 94/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.0608 - val_loss: 0.1406\n",
      "Epoch 95/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.0608 - val_loss: 0.1389\n",
      "Epoch 96/100\n",
      "2/2 - 0s - 224ms/step - loss: 0.0605 - val_loss: 0.1382\n",
      "Epoch 97/100\n",
      "2/2 - 1s - 257ms/step - loss: 0.0602 - val_loss: 0.1383\n",
      "Epoch 98/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0600 - val_loss: 0.1390\n",
      "Epoch 99/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.0602 - val_loss: 0.1371\n",
      "Epoch 100/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.0604 - val_loss: 0.1329\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "未来20天预测汇率：\n",
      "[1.581202  1.5812485 1.5820199 1.5835209 1.5856566 1.5882906 1.5912806\n",
      " 1.5944985 1.5978379 1.6012164 1.604572  1.607861  1.6110516 1.6141218\n",
      " 1.6170567 1.6198452 1.6224793 1.6249541 1.6272655 1.6294116]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "\n",
    "def predict(name:str):\n",
    "    #CNY_HKD_to_exchange_rate.csv\n",
    "    model = CurrencyLSTMModel(currency_name=name, data_path=f\"CNY_{name}_to_exchange_rate.csv\", look_back=100)\n",
    "    model.train()\n",
    "    model.save(f\"{name}_model.keras\")\n",
    "    model.load(f\"{name}_model.keras\")\n",
    "    joblib.dump(model.scaler, 'scaler.save')\n",
    "    model.scaler = joblib.load('scaler.save')\n",
    "    csvname = f\"CNY_{name}_to_exchange_rate.csv\"\n",
    "    # 读取原始数据\n",
    "    dataset = pd.read_csv(csvname, header=0, index_col=0)\n",
    "    values = dataset.values.astype('float32')\n",
    "\n",
    "    # 归一化\n",
    "    scaled = model.scaler.transform(values)\n",
    "\n",
    "    # 取最近100天\n",
    "    last_100 = scaled[-100:]  # shape: (100, 1)\n",
    "\n",
    "    # 递归预测未来20天\n",
    "    future_steps = 20\n",
    "    future_preds = []\n",
    "\n",
    "    input_seq = last_100.reshape((1, 100, 1))\n",
    "\n",
    "    for _ in range(future_steps):\n",
    "        yhat = model.predict(input_seq)\n",
    "        future_preds.append(yhat[0, 0])\n",
    "        # 更新输入序列：去掉最早一天，加上最新预测\n",
    "        new_input = np.append(input_seq[0, 1:, 0], yhat[0, 0])\n",
    "        input_seq = new_input.reshape((1, 100, 1))\n",
    "\n",
    "    # 反归一化\n",
    "    future_preds = np.array(future_preds).reshape(-1, 1)\n",
    "    future_real = model.scaler.inverse_transform(future_preds)\n",
    "    print(\"未来20天预测汇率：\")\n",
    "    print(future_real.flatten())\n",
    "    \n",
    "\n",
    "targets = [\"JPY\", \"KRW\", \"SGD\", \"THB\", \"HKD\", \"MYR\"]  # 多个目标货币\n",
    "for target in targets:\n",
    "    print(f\"预测 {target} 对人民币的汇率：\")\n",
    "    predict(target)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a841e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rprp/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 5s - 3s/step - loss: 2.4845 - val_loss: 2.7295 - learning_rate: 1.0000e-03\n",
      "Epoch 2/100\n",
      "2/2 - 1s - 279ms/step - loss: 2.2908 - val_loss: 2.3332 - learning_rate: 1.0000e-03\n",
      "Epoch 3/100\n",
      "2/2 - 0s - 243ms/step - loss: 2.1108 - val_loss: 2.0194 - learning_rate: 1.0000e-03\n",
      "Epoch 4/100\n",
      "2/2 - 0s - 211ms/step - loss: 2.0972 - val_loss: 1.9979 - learning_rate: 1.0000e-03\n",
      "Epoch 5/100\n",
      "2/2 - 0s - 200ms/step - loss: 1.9804 - val_loss: 2.0662 - learning_rate: 1.0000e-03\n",
      "Epoch 6/100\n",
      "2/2 - 0s - 194ms/step - loss: 1.8952 - val_loss: 2.0555 - learning_rate: 1.0000e-03\n",
      "Epoch 7/100\n",
      "2/2 - 0s - 190ms/step - loss: 1.8131 - val_loss: 1.9643 - learning_rate: 1.0000e-03\n",
      "Epoch 8/100\n",
      "2/2 - 0s - 202ms/step - loss: 1.7286 - val_loss: 1.8324 - learning_rate: 1.0000e-03\n",
      "Epoch 9/100\n",
      "2/2 - 0s - 202ms/step - loss: 1.6483 - val_loss: 1.6886 - learning_rate: 1.0000e-03\n",
      "Epoch 10/100\n",
      "2/2 - 0s - 209ms/step - loss: 1.5892 - val_loss: 1.5777 - learning_rate: 1.0000e-03\n",
      "Epoch 11/100\n",
      "2/2 - 0s - 246ms/step - loss: 1.5177 - val_loss: 1.5171 - learning_rate: 1.0000e-03\n",
      "Epoch 12/100\n",
      "2/2 - 0s - 239ms/step - loss: 1.4647 - val_loss: 1.4968 - learning_rate: 1.0000e-03\n",
      "Epoch 13/100\n",
      "2/2 - 0s - 223ms/step - loss: 1.4011 - val_loss: 1.4803 - learning_rate: 1.0000e-03\n",
      "Epoch 14/100\n",
      "2/2 - 0s - 238ms/step - loss: 1.3444 - val_loss: 1.4383 - learning_rate: 1.0000e-03\n",
      "Epoch 15/100\n",
      "2/2 - 1s - 358ms/step - loss: 1.2748 - val_loss: 1.3705 - learning_rate: 1.0000e-03\n",
      "Epoch 16/100\n",
      "2/2 - 1s - 268ms/step - loss: 1.2235 - val_loss: 1.2823 - learning_rate: 1.0000e-03\n",
      "Epoch 17/100\n",
      "2/2 - 1s - 259ms/step - loss: 1.1677 - val_loss: 1.1837 - learning_rate: 1.0000e-03\n",
      "Epoch 18/100\n",
      "2/2 - 1s - 284ms/step - loss: 1.1216 - val_loss: 1.1002 - learning_rate: 1.0000e-03\n",
      "Epoch 19/100\n",
      "2/2 - 0s - 230ms/step - loss: 1.0806 - val_loss: 1.0470 - learning_rate: 1.0000e-03\n",
      "Epoch 20/100\n",
      "2/2 - 0s - 246ms/step - loss: 1.0393 - val_loss: 1.0198 - learning_rate: 1.0000e-03\n",
      "Epoch 21/100\n",
      "2/2 - 0s - 247ms/step - loss: 0.9833 - val_loss: 1.0043 - learning_rate: 1.0000e-03\n",
      "Epoch 22/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.9484 - val_loss: 0.9773 - learning_rate: 1.0000e-03\n",
      "Epoch 23/100\n",
      "2/2 - 1s - 348ms/step - loss: 0.9032 - val_loss: 0.9181 - learning_rate: 1.0000e-03\n",
      "Epoch 24/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.8692 - val_loss: 0.8447 - learning_rate: 1.0000e-03\n",
      "Epoch 25/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.8306 - val_loss: 0.7836 - learning_rate: 1.0000e-03\n",
      "Epoch 26/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.7885 - val_loss: 0.7523 - learning_rate: 1.0000e-03\n",
      "Epoch 27/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.7611 - val_loss: 0.7440 - learning_rate: 1.0000e-03\n",
      "Epoch 28/100\n",
      "2/2 - 0s - 233ms/step - loss: 0.7359 - val_loss: 0.7199 - learning_rate: 1.0000e-03\n",
      "Epoch 29/100\n",
      "2/2 - 1s - 263ms/step - loss: 0.7032 - val_loss: 0.6733 - learning_rate: 1.0000e-03\n",
      "Epoch 30/100\n",
      "2/2 - 1s - 255ms/step - loss: 0.6600 - val_loss: 0.6217 - learning_rate: 1.0000e-03\n",
      "Epoch 31/100\n",
      "2/2 - 1s - 314ms/step - loss: 0.6412 - val_loss: 0.5988 - learning_rate: 1.0000e-03\n",
      "Epoch 32/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.6214 - val_loss: 0.5711 - learning_rate: 1.0000e-03\n",
      "Epoch 33/100\n",
      "2/2 - 1s - 280ms/step - loss: 0.5978 - val_loss: 0.5476 - learning_rate: 1.0000e-03\n",
      "Epoch 34/100\n",
      "2/2 - 0s - 218ms/step - loss: 0.5713 - val_loss: 0.5269 - learning_rate: 1.0000e-03\n",
      "Epoch 35/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.5455 - val_loss: 0.5354 - learning_rate: 1.0000e-03\n",
      "Epoch 36/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.5231 - val_loss: 0.5495 - learning_rate: 1.0000e-03\n",
      "Epoch 37/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.5072 - val_loss: 0.4999 - learning_rate: 1.0000e-03\n",
      "Epoch 38/100\n",
      "2/2 - 1s - 257ms/step - loss: 0.4886 - val_loss: 0.4665 - learning_rate: 1.0000e-03\n",
      "Epoch 39/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.4669 - val_loss: 0.4713 - learning_rate: 1.0000e-03\n",
      "Epoch 40/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.4458 - val_loss: 0.4869 - learning_rate: 1.0000e-03\n",
      "Epoch 41/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.4253 - val_loss: 0.4787 - learning_rate: 1.0000e-03\n",
      "Epoch 42/100\n",
      "2/2 - 1s - 264ms/step - loss: 0.4117 - val_loss: 0.4173 - learning_rate: 1.0000e-03\n",
      "Epoch 43/100\n",
      "2/2 - 1s - 256ms/step - loss: 0.3978 - val_loss: 0.4203 - learning_rate: 1.0000e-03\n",
      "Epoch 44/100\n",
      "2/2 - 0s - 233ms/step - loss: 0.3794 - val_loss: 0.4322 - learning_rate: 1.0000e-03\n",
      "Epoch 45/100\n",
      "2/2 - 0s - 236ms/step - loss: 0.3712 - val_loss: 0.4047 - learning_rate: 1.0000e-03\n",
      "Epoch 46/100\n",
      "2/2 - 0s - 239ms/step - loss: 0.3597 - val_loss: 0.3806 - learning_rate: 1.0000e-03\n",
      "Epoch 47/100\n",
      "2/2 - 0s - 206ms/step - loss: 0.3435 - val_loss: 0.3870 - learning_rate: 1.0000e-03\n",
      "Epoch 48/100\n",
      "2/2 - 0s - 216ms/step - loss: 0.3320 - val_loss: 0.3564 - learning_rate: 1.0000e-03\n",
      "Epoch 49/100\n",
      "2/2 - 1s - 365ms/step - loss: 0.3205 - val_loss: 0.3004 - learning_rate: 1.0000e-03\n",
      "Epoch 50/100\n",
      "2/2 - 0s - 241ms/step - loss: 0.3124 - val_loss: 0.2911 - learning_rate: 1.0000e-03\n",
      "Epoch 51/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.3018 - val_loss: 0.2846 - learning_rate: 1.0000e-03\n",
      "Epoch 52/100\n",
      "2/2 - 0s - 205ms/step - loss: 0.2941 - val_loss: 0.3178 - learning_rate: 1.0000e-03\n",
      "Epoch 53/100\n",
      "2/2 - 0s - 233ms/step - loss: 0.2859 - val_loss: 0.3258 - learning_rate: 1.0000e-03\n",
      "Epoch 54/100\n",
      "2/2 - 1s - 354ms/step - loss: 0.2687 - val_loss: 0.2883 - learning_rate: 1.0000e-03\n",
      "Epoch 55/100\n",
      "2/2 - 1s - 556ms/step - loss: 0.2709 - val_loss: 0.2569 - learning_rate: 1.0000e-03\n",
      "Epoch 56/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.2546 - val_loss: 0.2551 - learning_rate: 1.0000e-03\n",
      "Epoch 57/100\n",
      "2/2 - 1s - 332ms/step - loss: 0.2446 - val_loss: 0.2807 - learning_rate: 1.0000e-03\n",
      "Epoch 58/100\n",
      "2/2 - 0s - 240ms/step - loss: 0.2441 - val_loss: 0.2461 - learning_rate: 1.0000e-03\n",
      "Epoch 59/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.2375 - val_loss: 0.2544 - learning_rate: 1.0000e-03\n",
      "Epoch 60/100\n",
      "2/2 - 0s - 225ms/step - loss: 0.2272 - val_loss: 0.2393 - learning_rate: 1.0000e-03\n",
      "Epoch 61/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.2189 - val_loss: 0.2338 - learning_rate: 1.0000e-03\n",
      "Epoch 62/100\n",
      "2/2 - 0s - 246ms/step - loss: 0.2140 - val_loss: 0.2273 - learning_rate: 1.0000e-03\n",
      "Epoch 63/100\n",
      "2/2 - 0s - 229ms/step - loss: 0.2124 - val_loss: 0.2288 - learning_rate: 1.0000e-03\n",
      "Epoch 64/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.2036 - val_loss: 0.2213 - learning_rate: 1.0000e-03\n",
      "Epoch 65/100\n",
      "2/2 - 1s - 254ms/step - loss: 0.1963 - val_loss: 0.2324 - learning_rate: 1.0000e-03\n",
      "Epoch 66/100\n",
      "2/2 - 0s - 221ms/step - loss: 0.1940 - val_loss: 0.2248 - learning_rate: 1.0000e-03\n",
      "Epoch 67/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.1845 - val_loss: 0.2217 - learning_rate: 1.0000e-03\n",
      "Epoch 68/100\n",
      "2/2 - 1s - 269ms/step - loss: 0.1835 - val_loss: 0.2210 - learning_rate: 1.0000e-03\n",
      "Epoch 69/100\n",
      "2/2 - 0s - 221ms/step - loss: 0.1854 - val_loss: 0.2180 - learning_rate: 1.0000e-03\n",
      "Epoch 70/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.1766 - val_loss: 0.2171 - learning_rate: 1.0000e-03\n",
      "Epoch 71/100\n",
      "2/2 - 0s - 244ms/step - loss: 0.1761 - val_loss: 0.2174 - learning_rate: 1.0000e-03\n",
      "Epoch 72/100\n",
      "2/2 - 0s - 228ms/step - loss: 0.1733 - val_loss: 0.2174 - learning_rate: 1.0000e-03\n",
      "Epoch 73/100\n",
      "2/2 - 0s - 245ms/step - loss: 0.1658 - val_loss: 0.2205 - learning_rate: 1.0000e-03\n",
      "Epoch 74/100\n",
      "2/2 - 0s - 225ms/step - loss: 0.1641 - val_loss: 0.2228 - learning_rate: 1.0000e-03\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2/2 - 0s - 225ms/step - loss: 0.1628 - val_loss: 0.2185 - learning_rate: 1.0000e-03\n",
      "Epoch 76/100\n",
      "2/2 - 0s - 249ms/step - loss: 0.1539 - val_loss: 0.2246 - learning_rate: 5.0000e-04\n",
      "Epoch 77/100\n",
      "2/2 - 0s - 242ms/step - loss: 0.1562 - val_loss: 0.2108 - learning_rate: 5.0000e-04\n",
      "Epoch 78/100\n",
      "2/2 - 0s - 233ms/step - loss: 0.1521 - val_loss: 0.2197 - learning_rate: 5.0000e-04\n",
      "Epoch 79/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.1557 - val_loss: 0.2226 - learning_rate: 5.0000e-04\n",
      "Epoch 80/100\n",
      "2/2 - 0s - 226ms/step - loss: 0.1504 - val_loss: 0.2113 - learning_rate: 5.0000e-04\n",
      "Epoch 81/100\n",
      "2/2 - 0s - 223ms/step - loss: 0.1512 - val_loss: 0.2020 - learning_rate: 5.0000e-04\n",
      "Epoch 82/100\n",
      "2/2 - 0s - 234ms/step - loss: 0.1510 - val_loss: 0.2006 - learning_rate: 5.0000e-04\n",
      "Epoch 83/100\n",
      "2/2 - 0s - 224ms/step - loss: 0.1466 - val_loss: 0.1973 - learning_rate: 5.0000e-04\n",
      "Epoch 84/100\n",
      "2/2 - 0s - 228ms/step - loss: 0.1435 - val_loss: 0.1995 - learning_rate: 5.0000e-04\n",
      "Epoch 85/100\n",
      "2/2 - 1s - 251ms/step - loss: 0.1451 - val_loss: 0.1980 - learning_rate: 5.0000e-04\n",
      "Epoch 86/100\n",
      "2/2 - 0s - 238ms/step - loss: 0.1432 - val_loss: 0.1931 - learning_rate: 5.0000e-04\n",
      "Epoch 87/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.1431 - val_loss: 0.1928 - learning_rate: 5.0000e-04\n",
      "Epoch 88/100\n",
      "2/2 - 0s - 248ms/step - loss: 0.1426 - val_loss: 0.1963 - learning_rate: 5.0000e-04\n",
      "Epoch 89/100\n",
      "2/2 - 0s - 237ms/step - loss: 0.1392 - val_loss: 0.1957 - learning_rate: 5.0000e-04\n",
      "Epoch 90/100\n",
      "2/2 - 0s - 235ms/step - loss: 0.1455 - val_loss: 0.1961 - learning_rate: 5.0000e-04\n",
      "Epoch 91/100\n",
      "2/2 - 0s - 230ms/step - loss: 0.1377 - val_loss: 0.1963 - learning_rate: 5.0000e-04\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2/2 - 0s - 220ms/step - loss: 0.1395 - val_loss: 0.1960 - learning_rate: 5.0000e-04\n",
      "Epoch 93/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.1387 - val_loss: 0.1969 - learning_rate: 2.5000e-04\n",
      "Epoch 94/100\n",
      "2/2 - 0s - 221ms/step - loss: 0.1369 - val_loss: 0.1996 - learning_rate: 2.5000e-04\n",
      "Epoch 95/100\n",
      "2/2 - 0s - 220ms/step - loss: 0.1354 - val_loss: 0.2010 - learning_rate: 2.5000e-04\n",
      "Epoch 96/100\n",
      "2/2 - 0s - 232ms/step - loss: 0.1344 - val_loss: 0.1986 - learning_rate: 2.5000e-04\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2/2 - 0s - 232ms/step - loss: 0.1345 - val_loss: 0.1961 - learning_rate: 2.5000e-04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "未来20天预测汇率：\n",
      "[5.6001124 5.612041  5.622594  5.631067  5.6370616 5.640454  5.6413565\n",
      " 5.6400747 5.637032  5.632707  5.627544  5.6219277 5.6161447 5.6104183\n",
      " 5.6048427 5.5994453 5.5941787 5.5889783 5.5837884 5.5785413]\n"
     ]
    }
   ],
   "source": [
    "predict(\"SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a202c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
